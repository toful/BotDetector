{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "sys.path.append( os.getcwd()+'/modules' )\n",
    "import aux_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Loading datasets\n",
    "path = os.getcwd() \n",
    "os.chdir( \"/home/toful/Documents/DataSets/cresci-2017.csv/datasets_full.csv/\" )\n",
    "\n",
    "real = pd.read_csv( 'genuine_accounts.csv/genuine_accounts.csv/users.csv' )\n",
    "real = real.fillna( '' )\n",
    "real['knownbot'] = 0\n",
    "\n",
    "fakeFollowers = pd.read_csv('fake_followers.csv/fake_followers.csv/users.csv', na_filter=False)\n",
    "fakeFollowers = fakeFollowers.fillna( '' )\n",
    "fakeFollowers['knownbot'] = 1\n",
    "\n",
    "socialSpamBots1 = pd.read_csv('social_spambots_1.csv/social_spambots_1.csv/users.csv', na_filter=False)\n",
    "socialSpamBots1 = socialSpamBots1.fillna( '' )\n",
    "socialSpamBots1['knownbot'] = 1\n",
    "\n",
    "socialSpamBots2 = pd.read_csv('social_spambots_2.csv/social_spambots_2.csv/users.csv', na_filter=False)\n",
    "socialSpamBots2 = socialSpamBots2.fillna( '' )\n",
    "socialSpamBots2['knownbot'] = 1\n",
    "\n",
    "socialSpamBots3 = pd.read_csv('social_spambots_3.csv/social_spambots_3.csv/users.csv', na_filter=False)\n",
    "socialSpamBots3 = socialSpamBots3.fillna( '' )\n",
    "socialSpamBots3['knownbot'] = 1\n",
    "\n",
    "df_list = []\n",
    "\n",
    "df_list += [ shuffle( pd.concat( [ real, fakeFollowers ], sort=False ) ) ]\n",
    "df_list += [ shuffle( pd.concat( [ real, socialSpamBots1, socialSpamBots2, socialSpamBots3 ], sort=False ) ) ]\n",
    "df_list += [ shuffle( pd.concat( [ real, fakeFollowers, socialSpamBots1, socialSpamBots2, socialSpamBots3 ], sort=False ) ) ]\n",
    "\n",
    "fakeFollowers['knownbot'] = 2\n",
    "df_list += [ shuffle( pd.concat( [ real, fakeFollowers, socialSpamBots1, socialSpamBots2, socialSpamBots3 ], sort=False ) ) ]\n",
    "#df = shuffle( df )\n",
    "#print df.head()\n",
    "#print df.info()\n",
    "\n",
    "os.chdir( path )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6825 entries, 1289 to 1642\n",
      "Data columns (total 43 columns):\n",
      "id                                    6825 non-null int64\n",
      "name                                  6825 non-null object\n",
      "screen_name                           6825 non-null object\n",
      "statuses_count                        6825 non-null int64\n",
      "followers_count                       6825 non-null int64\n",
      "friends_count                         6825 non-null int64\n",
      "favourites_count                      6825 non-null int64\n",
      "listed_count                          6825 non-null int64\n",
      "url                                   6825 non-null object\n",
      "lang                                  6825 non-null object\n",
      "time_zone                             6825 non-null object\n",
      "location                              6825 non-null object\n",
      "default_profile                       6825 non-null object\n",
      "default_profile_image                 6825 non-null object\n",
      "geo_enabled                           6825 non-null object\n",
      "profile_image_url                     6825 non-null object\n",
      "profile_banner_url                    6825 non-null object\n",
      "profile_use_background_image          6825 non-null object\n",
      "profile_background_image_url_https    6825 non-null object\n",
      "profile_text_color                    6825 non-null object\n",
      "profile_image_url_https               6825 non-null object\n",
      "profile_sidebar_border_color          6825 non-null object\n",
      "profile_background_tile               6825 non-null object\n",
      "profile_sidebar_fill_color            6825 non-null object\n",
      "profile_background_image_url          6825 non-null object\n",
      "profile_background_color              6825 non-null object\n",
      "profile_link_color                    6825 non-null object\n",
      "utc_offset                            6825 non-null object\n",
      "is_translator                         6825 non-null object\n",
      "follow_request_sent                   6825 non-null object\n",
      "protected                             6825 non-null object\n",
      "verified                              6825 non-null object\n",
      "notifications                         6825 non-null object\n",
      "description                           6825 non-null object\n",
      "contributors_enabled                  6825 non-null object\n",
      "following                             6825 non-null object\n",
      "created_at                            6825 non-null object\n",
      "timestamp                             3474 non-null object\n",
      "crawled_at                            3474 non-null object\n",
      "updated                               6825 non-null object\n",
      "test_set_1                            3474 non-null float64\n",
      "test_set_2                            3474 non-null float64\n",
      "knownbot                              6825 non-null int64\n",
      "dtypes: float64(2), int64(7), object(34)\n",
      "memory usage: 2.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df_list[0].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/toful/Dropbox/Uni/5e_Curs/TFG_I/BotDetector/src\n"
     ]
    }
   ],
   "source": [
    "print( os.getcwd()  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6825, 18)\n",
      "                 id  profile_pic  def_profile_pic  has_screen_name  \\\n",
      "count  6.825000e+03       6825.0      6825.000000      6825.000000   \n",
      "mean   8.499737e+08          0.0         0.002784         0.000147   \n",
      "std    7.662248e+08          0.0         0.052693         0.012105   \n",
      "min    6.780330e+05          0.0         0.000000         0.000000   \n",
      "25%    2.597067e+08          0.0         0.000000         0.000000   \n",
      "50%    6.168972e+08          0.0         0.000000         0.000000   \n",
      "75%    1.174963e+09          0.0         0.000000         0.000000   \n",
      "max    3.164942e+09          0.0         1.000000         1.000000   \n",
      "\n",
      "       30followers  1000followers  1000friends    30friends  \\\n",
      "count  6825.000000    6825.000000  6825.000000  6825.000000   \n",
      "mean      0.492601       0.105788     0.076337     0.024469   \n",
      "std       0.499982       0.307588     0.265556     0.154511   \n",
      "min       0.000000       0.000000     0.000000     0.000000   \n",
      "25%       0.000000       0.000000     0.000000     0.000000   \n",
      "50%       0.000000       0.000000     0.000000     0.000000   \n",
      "75%       1.000000       0.000000     0.000000     0.000000   \n",
      "max       1.000000       1.000000     1.000000     1.000000   \n",
      "\n",
      "       twice_num_followers  fifty_FriendsFollowersRatio  \\\n",
      "count          6825.000000                  6825.000000   \n",
      "mean              0.588425                     0.091722   \n",
      "std               0.492155                     0.288654   \n",
      "min               0.000000                     0.000000   \n",
      "25%               0.000000                     0.000000   \n",
      "50%               1.000000                     0.000000   \n",
      "75%               1.000000                     0.000000   \n",
      "max               1.000000                     1.000000   \n",
      "\n",
      "       hundred_FriendsFollowersRatio       geoloc  banner_link     50tweets  \\\n",
      "count                    6825.000000  6825.000000  6825.000000  6825.000000   \n",
      "mean                        0.051722     0.663883     0.954725     0.410696   \n",
      "std                         0.221481     0.472414     0.207921     0.491996   \n",
      "min                         0.000000     0.000000     0.000000     0.000000   \n",
      "25%                         0.000000     0.000000     1.000000     0.000000   \n",
      "50%                         0.000000     1.000000     1.000000     0.000000   \n",
      "75%                         0.000000     1.000000     1.000000     1.000000   \n",
      "max                         1.000000     1.000000     1.000000     1.000000   \n",
      "\n",
      "        20statuses  NeverTweeted  has_description     knownbot  \n",
      "count  6825.000000   6825.000000      6825.000000  6825.000000  \n",
      "mean      0.184615      0.020220         0.212747     0.490989  \n",
      "std       0.388014      0.140762         0.409280     0.499955  \n",
      "min       0.000000      0.000000         0.000000     0.000000  \n",
      "25%       0.000000      0.000000         0.000000     0.000000  \n",
      "50%       0.000000      0.000000         0.000000     0.000000  \n",
      "75%       0.000000      0.000000         0.000000     1.000000  \n",
      "max       1.000000      1.000000         1.000000     1.000000  \n",
      "['id' 'profile_pic' 'def_profile_pic' 'has_screen_name' '30followers'\n",
      " '1000followers' '1000friends' '30friends' 'twice_num_followers'\n",
      " 'fifty_FriendsFollowersRatio' 'hundred_FriendsFollowersRatio' 'geoloc'\n",
      " 'banner_link' '50tweets' '20statuses' 'NeverTweeted' 'has_description'\n",
      " 'knownbot']\n",
      "(8386, 18)\n",
      "                 id  profile_pic  def_profile_pic  has_screen_name  \\\n",
      "count  8.386000e+03       8386.0      8386.000000      8386.000000   \n",
      "mean   1.471678e+09          0.0         0.007155         0.000119   \n",
      "std    1.008270e+09          0.0         0.084288         0.010920   \n",
      "min    6.780330e+05          0.0         0.000000         0.000000   \n",
      "25%    4.661508e+08          0.0         0.000000         0.000000   \n",
      "50%    2.213073e+09          0.0         0.000000         0.000000   \n",
      "75%    2.362677e+09          0.0         0.000000         0.000000   \n",
      "max    3.164942e+09          0.0         1.000000         1.000000   \n",
      "\n",
      "       30followers  1000followers  1000friends    30friends  \\\n",
      "count  8386.000000    8386.000000  8386.000000  8386.000000   \n",
      "mean      0.477105       0.147508     0.147269     0.064155   \n",
      "std       0.499505       0.354633     0.354395     0.245043   \n",
      "min       0.000000       0.000000     0.000000     0.000000   \n",
      "25%       0.000000       0.000000     0.000000     0.000000   \n",
      "50%       0.000000       0.000000     0.000000     0.000000   \n",
      "75%       1.000000       0.000000     0.000000     0.000000   \n",
      "max       1.000000       1.000000     1.000000     1.000000   \n",
      "\n",
      "       twice_num_followers  fifty_FriendsFollowersRatio  \\\n",
      "count          8386.000000                  8386.000000   \n",
      "mean              0.519795                     0.041975   \n",
      "std               0.499638                     0.200543   \n",
      "min               0.000000                     0.000000   \n",
      "25%               0.000000                     0.000000   \n",
      "50%               1.000000                     0.000000   \n",
      "75%               1.000000                     0.000000   \n",
      "max               1.000000                     1.000000   \n",
      "\n",
      "       hundred_FriendsFollowersRatio       geoloc  banner_link     50tweets  \\\n",
      "count                    8386.000000  8386.000000  8386.000000  8386.000000   \n",
      "mean                        0.041975     0.739089     0.963153     0.189959   \n",
      "std                         0.200543     0.439158     0.188398     0.392292   \n",
      "min                         0.000000     0.000000     0.000000     0.000000   \n",
      "25%                         0.000000     0.000000     1.000000     0.000000   \n",
      "50%                         0.000000     1.000000     1.000000     0.000000   \n",
      "75%                         0.000000     1.000000     1.000000     0.000000   \n",
      "max                         1.000000     1.000000     1.000000     1.000000   \n",
      "\n",
      "        20statuses  NeverTweeted  has_description     knownbot  \n",
      "count  8386.000000        8386.0      8386.000000  8386.000000  \n",
      "mean      0.003339           0.0         0.461960     0.585738  \n",
      "std       0.057690           0.0         0.498581     0.492623  \n",
      "min       0.000000           0.0         0.000000     0.000000  \n",
      "25%       0.000000           0.0         0.000000     0.000000  \n",
      "50%       0.000000           0.0         0.000000     1.000000  \n",
      "75%       0.000000           0.0         1.000000     1.000000  \n",
      "max       1.000000           0.0         1.000000     1.000000  \n",
      "['id' 'profile_pic' 'def_profile_pic' 'has_screen_name' '30followers'\n",
      " '1000followers' '1000friends' '30friends' 'twice_num_followers'\n",
      " 'fifty_FriendsFollowersRatio' 'hundred_FriendsFollowersRatio' 'geoloc'\n",
      " 'banner_link' '50tweets' '20statuses' 'NeverTweeted' 'has_description'\n",
      " 'knownbot']\n",
      "(11737, 18)\n",
      "                 id  profile_pic  def_profile_pic  has_screen_name  \\\n",
      "count  1.173700e+04      11737.0     11737.000000     11737.000000   \n",
      "mean   1.263988e+09          0.0         0.005623         0.000085   \n",
      "std    9.364116e+08          0.0         0.074780         0.009230   \n",
      "min    6.780330e+05          0.0         0.000000         0.000000   \n",
      "25%    4.662568e+08          0.0         0.000000         0.000000   \n",
      "50%    1.127956e+09          0.0         0.000000         0.000000   \n",
      "75%    2.357009e+09          0.0         0.000000         0.000000   \n",
      "max    3.164942e+09          0.0         1.000000         1.000000   \n",
      "\n",
      "        30followers  1000followers   1000friends     30friends  \\\n",
      "count  11737.000000   11737.000000  11737.000000  11737.000000   \n",
      "mean       0.611741       0.105734      0.108631      0.053421   \n",
      "std        0.487375       0.307510      0.311189      0.224881   \n",
      "min        0.000000       0.000000      0.000000      0.000000   \n",
      "25%        0.000000       0.000000      0.000000      0.000000   \n",
      "50%        1.000000       0.000000      0.000000      0.000000   \n",
      "75%        1.000000       0.000000      0.000000      0.000000   \n",
      "max        1.000000       1.000000      1.000000      1.000000   \n",
      "\n",
      "       twice_num_followers  fifty_FriendsFollowersRatio  \\\n",
      "count         11737.000000                 11737.000000   \n",
      "mean              0.655789                     0.083326   \n",
      "std               0.475130                     0.276386   \n",
      "min               0.000000                     0.000000   \n",
      "25%               0.000000                     0.000000   \n",
      "50%               1.000000                     0.000000   \n",
      "75%               1.000000                     0.000000   \n",
      "max               1.000000                     1.000000   \n",
      "\n",
      "       hundred_FriendsFollowersRatio        geoloc   banner_link  \\\n",
      "count                   11737.000000  11737.000000  11737.000000   \n",
      "mean                        0.060066      0.801738      0.973673   \n",
      "std                         0.237620      0.398707      0.160113   \n",
      "min                         0.000000      0.000000      0.000000   \n",
      "25%                         0.000000      1.000000      1.000000   \n",
      "50%                         0.000000      1.000000      1.000000   \n",
      "75%                         0.000000      1.000000      1.000000   \n",
      "max                         1.000000      1.000000      1.000000   \n",
      "\n",
      "           50tweets    20statuses  NeverTweeted  has_description      knownbot  \n",
      "count  11737.000000  11737.000000  11737.000000     11737.000000  11737.000000  \n",
      "mean       0.369941      0.107864      0.011758         0.421488      0.704013  \n",
      "std        0.482809      0.310222      0.107798         0.493818      0.456505  \n",
      "min        0.000000      0.000000      0.000000         0.000000      0.000000  \n",
      "25%        0.000000      0.000000      0.000000         0.000000      0.000000  \n",
      "50%        0.000000      0.000000      0.000000         0.000000      1.000000  \n",
      "75%        1.000000      0.000000      0.000000         1.000000      1.000000  \n",
      "max        1.000000      1.000000      1.000000         1.000000      1.000000  \n",
      "['id' 'profile_pic' 'def_profile_pic' 'has_screen_name' '30followers'\n",
      " '1000followers' '1000friends' '30friends' 'twice_num_followers'\n",
      " 'fifty_FriendsFollowersRatio' 'hundred_FriendsFollowersRatio' 'geoloc'\n",
      " 'banner_link' '50tweets' '20statuses' 'NeverTweeted' 'has_description'\n",
      " 'knownbot']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11737, 18)\n",
      "                 id  profile_pic  def_profile_pic  has_screen_name  \\\n",
      "count  1.173700e+04      11737.0     11737.000000     11737.000000   \n",
      "mean   1.263988e+09          0.0         0.005623         0.000085   \n",
      "std    9.364116e+08          0.0         0.074780         0.009230   \n",
      "min    6.780330e+05          0.0         0.000000         0.000000   \n",
      "25%    4.662568e+08          0.0         0.000000         0.000000   \n",
      "50%    1.127956e+09          0.0         0.000000         0.000000   \n",
      "75%    2.357009e+09          0.0         0.000000         0.000000   \n",
      "max    3.164942e+09          0.0         1.000000         1.000000   \n",
      "\n",
      "        30followers  1000followers   1000friends     30friends  \\\n",
      "count  11737.000000   11737.000000  11737.000000  11737.000000   \n",
      "mean       0.611741       0.105734      0.108631      0.053421   \n",
      "std        0.487375       0.307510      0.311189      0.224881   \n",
      "min        0.000000       0.000000      0.000000      0.000000   \n",
      "25%        0.000000       0.000000      0.000000      0.000000   \n",
      "50%        1.000000       0.000000      0.000000      0.000000   \n",
      "75%        1.000000       0.000000      0.000000      0.000000   \n",
      "max        1.000000       1.000000      1.000000      1.000000   \n",
      "\n",
      "       twice_num_followers  fifty_FriendsFollowersRatio  \\\n",
      "count         11737.000000                 11737.000000   \n",
      "mean              0.655789                     0.083326   \n",
      "std               0.475130                     0.276386   \n",
      "min               0.000000                     0.000000   \n",
      "25%               0.000000                     0.000000   \n",
      "50%               1.000000                     0.000000   \n",
      "75%               1.000000                     0.000000   \n",
      "max               1.000000                     1.000000   \n",
      "\n",
      "       hundred_FriendsFollowersRatio        geoloc   banner_link  \\\n",
      "count                   11737.000000  11737.000000  11737.000000   \n",
      "mean                        0.060066      0.801738      0.973673   \n",
      "std                         0.237620      0.398707      0.160113   \n",
      "min                         0.000000      0.000000      0.000000   \n",
      "25%                         0.000000      1.000000      1.000000   \n",
      "50%                         0.000000      1.000000      1.000000   \n",
      "75%                         0.000000      1.000000      1.000000   \n",
      "max                         1.000000      1.000000      1.000000   \n",
      "\n",
      "           50tweets    20statuses  NeverTweeted  has_description      knownbot  \n",
      "count  11737.000000  11737.000000  11737.000000     11737.000000  11737.000000  \n",
      "mean       0.369941      0.107864      0.011758         0.421488      0.418506  \n",
      "std        0.482809      0.310222      0.107798         0.493818      0.493335  \n",
      "min        0.000000      0.000000      0.000000         0.000000      0.000000  \n",
      "25%        0.000000      0.000000      0.000000         0.000000      0.000000  \n",
      "50%        0.000000      0.000000      0.000000         0.000000      0.000000  \n",
      "75%        1.000000      0.000000      0.000000         1.000000      1.000000  \n",
      "max        1.000000      1.000000      1.000000         1.000000      1.000000  \n",
      "['id' 'profile_pic' 'def_profile_pic' 'has_screen_name' '30followers'\n",
      " '1000followers' '1000friends' '30friends' 'twice_num_followers'\n",
      " 'fifty_FriendsFollowersRatio' 'hundred_FriendsFollowersRatio' 'geoloc'\n",
      " 'banner_link' '50tweets' '20statuses' 'NeverTweeted' 'has_description'\n",
      " 'knownbot']\n"
     ]
    }
   ],
   "source": [
    "#Building the working datasets\n",
    "score_list = []\n",
    "for df in df_list:\n",
    "    score = pd.DataFrame()\n",
    "    score['id'] = df['id']\n",
    "\n",
    "    #score['lang-en'] = df.apply( lambda row: aux_functions.language (row), axis=1 )\n",
    "    score['profile_pic'] = df.apply( lambda row: aux_functions.profile_image (row), axis=1 ) #check this feature\n",
    "    score['def_profile_pic'] = df.apply( lambda row: aux_functions.def_profile_image (row), axis=1 )\n",
    "    score['has_screen_name'] = df.apply( lambda row: aux_functions.screen_name (row), axis=1 )\n",
    "    score['30followers'] = df.apply( lambda row: aux_functions.min_followers (row, 30), axis=1 )\n",
    "    score['1000followers'] = df.apply( lambda row: aux_functions.min_followers2 (row, 1000), axis=1 )\n",
    "    score['1000friends'] = df.apply( lambda row: aux_functions.min_friends (row, 1000), axis=1 )\n",
    "    score['30friends'] = df.apply( lambda row: aux_functions.min_friends2 (row, 30), axis=1 )\n",
    "    score['twice_num_followers'] = df.apply( lambda row: aux_functions.ratio_followers (row), axis=1 )\n",
    "    score['fifty_FriendsFollowersRatio'] = df.apply( lambda row: aux_functions.ratio_followers2 (row, 50), axis=1 )\n",
    "    score['hundred_FriendsFollowersRatio'] = df.apply( lambda row: aux_functions.ratio_followers2 (row, 100), axis=1 )\n",
    "    score['geoloc'] = df.apply( lambda row: aux_functions.location (row), axis=1 )\n",
    "    score['banner_link'] = df.apply( lambda row: aux_functions.profile_banner (row), axis=1 )\n",
    "    score['50tweets'] = df.apply( lambda row: aux_functions.tweets_written (row, 50), axis=1 )\n",
    "    score['20statuses'] = df.apply( lambda row: aux_functions.min_statuses (row, 20), axis=1 )\n",
    "    score['NeverTweeted'] = df.apply( lambda row: aux_functions.never_tweeted (row ), axis=1 )\n",
    "    score['has_description'] = df.apply( lambda row: aux_functions.description (row), axis=1 )\n",
    "    score['knownbot'] = df.apply( lambda row: aux_functions.knownbot (row), axis=1 )\n",
    "\n",
    "    print score.shape\n",
    "    print score.describe()\n",
    "    print score.columns.values\n",
    "    score_list += [ score ]\n",
    "    #score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics as mt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing the X and Y values for the machine learning analisis\n",
    "yy=[]\n",
    "XX=[]\n",
    "for score in score_list:\n",
    "    if 'knownbot' in score:\n",
    "        y = score['knownbot'].values # get the labels we want\n",
    "        X = score\n",
    "        del X['knownbot']\n",
    "        del X['id']\n",
    "        X = X.values # use everything else to predict\n",
    "        yy += [y]\n",
    "        XX += [X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "profile_pic\n",
      "def_profile_pic\n",
      "has_screen_name\n",
      "30followers\n",
      "1000followers\n",
      "1000friends\n",
      "30friends\n",
      "twice_num_followers\n",
      "fifty_FriendsFollowersRatio\n",
      "hundred_FriendsFollowersRatio\n",
      "geoloc\n",
      "banner_link\n",
      "50tweets\n",
      "20statuses\n",
      "NeverTweeted\n",
      "has_description\n"
     ]
    }
   ],
   "source": [
    "for elem in score_list[0].columns.values:\n",
    "    print elem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RF analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model( X, y, name ):\n",
    "    num_cv_iterations = 3\n",
    "    num_instances = len(y)\n",
    "    cv_object = ShuffleSplit( n_splits=num_cv_iterations, test_size = 0.2 )\n",
    "\n",
    "    # first we create a reusable logisitic regression and random forest objects\n",
    "    lr_clf = LogisticRegression( penalty='l2', C=1.0, class_weight=None ) # get object\n",
    "    rf_clf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=0)\n",
    "\n",
    "    iter_num=0\n",
    "    # the indices are the rows used for training and testing in each iteration\n",
    "    for train_indices, test_indices in cv_object.split( X, y ):\n",
    "        X_train = X[train_indices]\n",
    "        y_train = y[train_indices]\n",
    "        X_test = X[test_indices]\n",
    "        y_test = y[test_indices]\n",
    "\n",
    "        # train the reusable logisitc regression model on the training data\n",
    "        #lr_clf.fit( X_train, y_train ) # train object\n",
    "        #y_pred = lr_clf.predict( X_test ) # get test set precitions\n",
    "\n",
    "        rf_clf.fit( X_train, y_train ) # train object\n",
    "        y_pred = rf_clf.predict( X_test ) # get test set precitions\n",
    "        acc = mt.accuracy_score( y_test, y_pred )\n",
    "        cmat = mt.confusion_matrix( y_test, y_pred )\n",
    "        # now let's get the accuracy and confusion matrix for this iterations of training/testing\n",
    "        print \"\\n====Iteration\",iter_num,\" ====\"\n",
    "        print \"RANDOM FOREST\"        \n",
    "        print( mt.classification_report( y_test, y_pred ) )\n",
    "        print \"Accuracy Rate: \", acc\n",
    "        print('Misclassification Rate: {}'.format( np.divide(np.sum( [ float(cmat[0,1]), float(cmat[1,0]) ] ), np.sum(cmat) ) ) )\n",
    "        print('\\nTP - True Negative {}'.format(cmat[0,0]))\n",
    "        print('FP - False Positive {}'.format(cmat[0,1]))\n",
    "        print('FN - False Negative {}'.format(cmat[1,0]))\n",
    "        print('TP - True Positive {}'.format(cmat[1,1]))\n",
    "        \n",
    "        iter_num+=1\n",
    "    # save the model to disk\n",
    "    #if not os.path.exists( 'models' ):\n",
    "    #    os.makedirs( 'models' )\n",
    "    #str_ = 'models/randomForest_' + name + '_model.sav'\n",
    "    #print( \"Saving the model into the disk\\n\" )\n",
    "    #joblib.dump( rf_clf, str_ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a model to detect:fakeFollowers\n",
      "\n",
      "====Iteration 0  ====\n",
      "RANDOM FOREST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.97       688\n",
      "           1       0.98      0.95      0.97       677\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      1365\n",
      "   macro avg       0.97      0.97      0.97      1365\n",
      "weighted avg       0.97      0.97      0.97      1365\n",
      "\n",
      "Accuracy Rate:  0.9677655677655678\n",
      "Misclassification Rate: 0.0322344322344\n",
      "\n",
      "TP - True Negative 676\n",
      "FP - False Positive 12\n",
      "FN - False Negative 32\n",
      "TP - True Positive 645\n",
      "\n",
      "====Iteration 1  ====\n",
      "RANDOM FOREST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97       680\n",
      "           1       0.97      0.97      0.97       685\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      1365\n",
      "   macro avg       0.97      0.97      0.97      1365\n",
      "weighted avg       0.97      0.97      0.97      1365\n",
      "\n",
      "Accuracy Rate:  0.9677655677655678\n",
      "Misclassification Rate: 0.0322344322344\n",
      "\n",
      "TP - True Negative 659\n",
      "FP - False Positive 21\n",
      "FN - False Negative 23\n",
      "TP - True Positive 662\n",
      "\n",
      "====Iteration 2  ====\n",
      "RANDOM FOREST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96       688\n",
      "           1       0.97      0.96      0.96       677\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      1365\n",
      "   macro avg       0.96      0.96      0.96      1365\n",
      "weighted avg       0.96      0.96      0.96      1365\n",
      "\n",
      "Accuracy Rate:  0.9641025641025641\n",
      "Misclassification Rate: 0.0358974358974\n",
      "\n",
      "TP - True Negative 668\n",
      "FP - False Positive 20\n",
      "FN - False Negative 29\n",
      "TP - True Positive 648\n",
      "Creating a model to detect:spamBots\n",
      "\n",
      "====Iteration 0  ====\n",
      "RANDOM FOREST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.93       726\n",
      "           1       0.96      0.93      0.94       952\n",
      "\n",
      "   micro avg       0.94      0.94      0.94      1678\n",
      "   macro avg       0.93      0.94      0.93      1678\n",
      "weighted avg       0.94      0.94      0.94      1678\n",
      "\n",
      "Accuracy Rate:  0.935041716328963\n",
      "Misclassification Rate: 0.064958283671\n",
      "\n",
      "TP - True Negative 686\n",
      "FP - False Positive 40\n",
      "FN - False Negative 69\n",
      "TP - True Positive 883\n",
      "\n",
      "====Iteration 1  ====\n",
      "RANDOM FOREST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.94       688\n",
      "           1       0.97      0.94      0.95       990\n",
      "\n",
      "   micro avg       0.95      0.95      0.95      1678\n",
      "   macro avg       0.94      0.95      0.95      1678\n",
      "weighted avg       0.95      0.95      0.95      1678\n",
      "\n",
      "Accuracy Rate:  0.9469606674612634\n",
      "Misclassification Rate: 0.0530393325387\n",
      "\n",
      "TP - True Negative 657\n",
      "FP - False Positive 31\n",
      "FN - False Negative 58\n",
      "TP - True Positive 932\n",
      "\n",
      "====Iteration 2  ====\n",
      "RANDOM FOREST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91       686\n",
      "           1       0.95      0.92      0.94       992\n",
      "\n",
      "   micro avg       0.93      0.93      0.93      1678\n",
      "   macro avg       0.92      0.93      0.92      1678\n",
      "weighted avg       0.93      0.93      0.93      1678\n",
      "\n",
      "Accuracy Rate:  0.9266984505363528\n",
      "Misclassification Rate: 0.0733015494636\n",
      "\n",
      "TP - True Negative 641\n",
      "FP - False Positive 45\n",
      "FN - False Negative 78\n",
      "TP - True Positive 914\n",
      "Creating a model to detect:mix\n",
      "\n",
      "====Iteration 0  ====\n",
      "RANDOM FOREST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92       729\n",
      "           1       0.97      0.95      0.96      1619\n",
      "\n",
      "   micro avg       0.95      0.95      0.95      2348\n",
      "   macro avg       0.93      0.94      0.94      2348\n",
      "weighted avg       0.95      0.95      0.95      2348\n",
      "\n",
      "Accuracy Rate:  0.9476149914821125\n",
      "Misclassification Rate: 0.0523850085179\n",
      "\n",
      "TP - True Negative 683\n",
      "FP - False Positive 46\n",
      "FN - False Negative 77\n",
      "TP - True Positive 1542\n",
      "\n",
      "====Iteration 1  ====\n",
      "RANDOM FOREST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.92      0.91       703\n",
      "           1       0.97      0.95      0.96      1645\n",
      "\n",
      "   micro avg       0.94      0.94      0.94      2348\n",
      "   macro avg       0.93      0.94      0.93      2348\n",
      "weighted avg       0.94      0.94      0.94      2348\n",
      "\n",
      "Accuracy Rate:  0.942504258943782\n",
      "Misclassification Rate: 0.0574957410562\n",
      "\n",
      "TP - True Negative 649\n",
      "FP - False Positive 54\n",
      "FN - False Negative 81\n",
      "TP - True Positive 1564\n",
      "\n",
      "====Iteration 2  ====\n",
      "RANDOM FOREST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.92      0.90       716\n",
      "           1       0.96      0.95      0.96      1632\n",
      "\n",
      "   micro avg       0.94      0.94      0.94      2348\n",
      "   macro avg       0.93      0.93      0.93      2348\n",
      "weighted avg       0.94      0.94      0.94      2348\n",
      "\n",
      "Accuracy Rate:  0.9399488926746167\n",
      "Misclassification Rate: 0.0600511073254\n",
      "\n",
      "TP - True Negative 657\n",
      "FP - False Positive 59\n",
      "FN - False Negative 82\n",
      "TP - True Positive 1550\n"
     ]
    }
   ],
   "source": [
    "names = [ 'fakeFollowers', 'spamBots', 'mix' ]\n",
    "for i in range( len( names ) ):\n",
    "    print( \"Creating a model to detect:\" + names[i] )\n",
    "    train_model( XX[i], yy[i], names[i] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LR analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_LR( X, y, name ):\n",
    "    num_cv_iterations = 3\n",
    "    num_instances = len(y)\n",
    "    cv_object = ShuffleSplit( n_splits=num_cv_iterations, test_size = 0.2 )\n",
    "\n",
    "    # first we create a reusable logisitic regression and random forest objects\n",
    "    lr_clf = LogisticRegression( penalty='l2', C=1.0, class_weight=None ) # get object\n",
    "\n",
    "    iter_num=0\n",
    "    # the indices are the rows used for training and testing in each iteration\n",
    "    for train_indices, test_indices in cv_object.split( X, y ):\n",
    "        X_train = X[train_indices]\n",
    "        y_train = y[train_indices]\n",
    "        X_test = X[test_indices]\n",
    "        y_test = y[test_indices]\n",
    "\n",
    "        # train the reusable logisitc regression model on the training data\n",
    "        #lr_clf.fit( X_train, y_train ) # train object\n",
    "        #y_pred = lr_clf.predict( X_test ) # get test set precitions\n",
    "\n",
    "        lr_clf.fit( X_train, y_train ) # train object\n",
    "        y_pred = lr_clf.predict( X_test ) # get test set precitions\n",
    "        acc = mt.accuracy_score( y_test, y_pred )\n",
    "        cmat = mt.confusion_matrix( y_test, y_pred )\n",
    "        # now let's get the accuracy and confusion matrix for this iterations of training/testing\n",
    "        print \"\\n====Iteration\",iter_num,\" ====\"\n",
    "        print \"LOGISTIC REGRESSION\"        \n",
    "        print( mt.classification_report( y_test, y_pred ) )\n",
    "        print \"Accuracy Rate: \", acc\n",
    "        print('Misclassification Rate: {}'.format( np.divide(np.sum( [ float(cmat[0,1]), float(cmat[1,0]) ] ), np.sum(cmat) ) ) )\n",
    "        print('\\nTP - True Negative {}'.format(cmat[0,0]))\n",
    "        print('FP - False Positive {}'.format(cmat[0,1]))\n",
    "        print('FN - False Negative {}'.format(cmat[1,0]))\n",
    "        print('TP - True Positive {}'.format(cmat[1,1]))\n",
    "        \n",
    "        iter_num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a model to detect:fakeFollowers\n",
      "\n",
      "====Iteration 0  ====\n",
      "LOGISTIC REGRESSION\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       710\n",
      "           1       0.98      0.95      0.97       655\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      1365\n",
      "   macro avg       0.97      0.97      0.97      1365\n",
      "weighted avg       0.97      0.97      0.97      1365\n",
      "\n",
      "Accuracy Rate:  0.967032967032967\n",
      "Misclassification Rate: 0.032967032967\n",
      "\n",
      "TP - True Negative 696\n",
      "FP - False Positive 14\n",
      "FN - False Negative 31\n",
      "TP - True Positive 624\n",
      "\n",
      "====Iteration 1  ====\n",
      "LOGISTIC REGRESSION\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       717\n",
      "           1       0.97      0.96      0.97       648\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      1365\n",
      "   macro avg       0.97      0.97      0.97      1365\n",
      "weighted avg       0.97      0.97      0.97      1365\n",
      "\n",
      "Accuracy Rate:  0.9692307692307692\n",
      "Misclassification Rate: 0.0307692307692\n",
      "\n",
      "TP - True Negative 701\n",
      "FP - False Positive 16\n",
      "FN - False Negative 26\n",
      "TP - True Positive 622\n",
      "\n",
      "====Iteration 2  ====\n",
      "LOGISTIC REGRESSION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96       696\n",
      "           1       0.97      0.95      0.96       669\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      1365\n",
      "   macro avg       0.96      0.96      0.96      1365\n",
      "weighted avg       0.96      0.96      0.96      1365\n",
      "\n",
      "Accuracy Rate:  0.958974358974359\n",
      "Misclassification Rate: 0.0410256410256\n",
      "\n",
      "TP - True Negative 676\n",
      "FP - False Positive 20\n",
      "FN - False Negative 36\n",
      "TP - True Positive 633\n",
      "Creating a model to detect:spamBots\n",
      "\n",
      "====Iteration 0  ====\n",
      "LOGISTIC REGRESSION\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.89      0.90       711\n",
      "           1       0.92      0.94      0.93       967\n",
      "\n",
      "   micro avg       0.91      0.91      0.91      1678\n",
      "   macro avg       0.91      0.91      0.91      1678\n",
      "weighted avg       0.91      0.91      0.91      1678\n",
      "\n",
      "Accuracy Rate:  0.9147794994040525\n",
      "Misclassification Rate: 0.0852205005959\n",
      "\n",
      "TP - True Negative 630\n",
      "FP - False Positive 81\n",
      "FN - False Negative 62\n",
      "TP - True Positive 905\n",
      "\n",
      "====Iteration 1  ====\n",
      "LOGISTIC REGRESSION\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92       681\n",
      "           1       0.94      0.95      0.94       997\n",
      "\n",
      "   micro avg       0.93      0.93      0.93      1678\n",
      "   macro avg       0.93      0.93      0.93      1678\n",
      "weighted avg       0.93      0.93      0.93      1678\n",
      "\n",
      "Accuracy Rate:  0.933849821215733\n",
      "Misclassification Rate: 0.0661501787843\n",
      "\n",
      "TP - True Negative 620\n",
      "FP - False Positive 61\n",
      "FN - False Negative 50\n",
      "TP - True Positive 947\n",
      "\n",
      "====Iteration 2  ====\n",
      "LOGISTIC REGRESSION\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92       697\n",
      "           1       0.94      0.95      0.94       981\n",
      "\n",
      "   micro avg       0.93      0.93      0.93      1678\n",
      "   macro avg       0.93      0.93      0.93      1678\n",
      "weighted avg       0.93      0.93      0.93      1678\n",
      "\n",
      "Accuracy Rate:  0.932657926102503\n",
      "Misclassification Rate: 0.0673420738975\n",
      "\n",
      "TP - True Negative 633\n",
      "FP - False Positive 64\n",
      "FN - False Negative 49\n",
      "TP - True Positive 932\n",
      "Creating a model to detect:mix\n",
      "\n",
      "====Iteration 0  ====\n",
      "LOGISTIC REGRESSION\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.92      0.90       660\n",
      "           1       0.97      0.95      0.96      1688\n",
      "\n",
      "   micro avg       0.94      0.94      0.94      2348\n",
      "   macro avg       0.93      0.94      0.93      2348\n",
      "weighted avg       0.95      0.94      0.94      2348\n",
      "\n",
      "Accuracy Rate:  0.9442078364565588\n",
      "Misclassification Rate: 0.0557921635434\n",
      "\n",
      "TP - True Negative 607\n",
      "FP - False Positive 53\n",
      "FN - False Negative 78\n",
      "TP - True Positive 1610\n",
      "\n",
      "====Iteration 1  ====\n",
      "LOGISTIC REGRESSION\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.90      0.90       682\n",
      "           1       0.96      0.96      0.96      1666\n",
      "\n",
      "   micro avg       0.94      0.94      0.94      2348\n",
      "   macro avg       0.93      0.93      0.93      2348\n",
      "weighted avg       0.94      0.94      0.94      2348\n",
      "\n",
      "Accuracy Rate:  0.9412265758091993\n",
      "Misclassification Rate: 0.0587734241908\n",
      "\n",
      "TP - True Negative 617\n",
      "FP - False Positive 65\n",
      "FN - False Negative 73\n",
      "TP - True Positive 1593\n",
      "\n",
      "====Iteration 2  ====\n",
      "LOGISTIC REGRESSION\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.90       719\n",
      "           1       0.96      0.95      0.95      1629\n",
      "\n",
      "   micro avg       0.93      0.93      0.93      2348\n",
      "   macro avg       0.92      0.93      0.92      2348\n",
      "weighted avg       0.94      0.93      0.94      2348\n",
      "\n",
      "Accuracy Rate:  0.9348381601362862\n",
      "Misclassification Rate: 0.0651618398637\n",
      "\n",
      "TP - True Negative 654\n",
      "FP - False Positive 65\n",
      "FN - False Negative 88\n",
      "TP - True Positive 1541\n"
     ]
    }
   ],
   "source": [
    "names = [ 'fakeFollowers', 'spamBots', 'mix' ]\n",
    "for i in range( len( names ) ):\n",
    "    print( \"Creating a model to detect:\" + names[i] )\n",
    "    train_model_LR( XX[i], yy[i], names[i] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_nneighbors_analysis( X, y ):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\n",
    "    error_rate = []\n",
    "\n",
    "    for i in range(1,40):\n",
    "        knn = KNeighborsClassifier( n_neighbors = i )\n",
    "        knn.fit( X_train, y_train )\n",
    "        y_pred = knn.predict( X_test )\n",
    "        error_rate.append( np.mean( y_pred != y_test) )\n",
    "    \n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.plot(range(1,40), error_rate, color='blue', linestyle='dashed', marker='o', markerfacecolor='red', markersize=10)\n",
    "    plt.title('Error Rate vs. K-Values')\n",
    "    plt.xlabel('K-Values')\n",
    "    plt.ylabel('Error Rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_analysis( X, y, neighbors ):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\n",
    "    knn = KNeighborsClassifier( n_neighbors=neighbors )\n",
    "    knn.fit( X_train, y_train )\n",
    "    y_pred = knn.predict( X_test )\n",
    "    acc = mt.accuracy_score( y_test, y_pred )\n",
    "    cmat = mt.confusion_matrix( y_test, y_pred )\n",
    "    print( mt.classification_report( y_test, y_pred ) )\n",
    "    print \"Accuracy Rate: \", acc\n",
    "    print('Misclassification Rate: {}'.format( np.divide(np.sum( [ float(cmat[0,1]), float(cmat[1,0]) ] ), np.sum(cmat) ) ) )\n",
    "    print('\\nTP - True Negative {}'.format(cmat[0,0]))\n",
    "    print('FP - False Positive {}'.format(cmat[0,1]))\n",
    "    print('FN - False Negative {}'.format(cmat[1,0]))\n",
    "    print('TP - True Positive {}'.format(cmat[1,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "knn_nneighbors_analysis( XX[0], yy[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97      1035\n",
      "           1       0.98      0.96      0.97      1013\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      2048\n",
      "   macro avg       0.97      0.97      0.97      2048\n",
      "weighted avg       0.97      0.97      0.97      2048\n",
      "\n",
      "Accuracy Rate:  0.96630859375\n",
      "Misclassification Rate: 0.03369140625\n",
      "\n",
      "TP - True Negative 1011\n",
      "FP - False Positive 24\n",
      "FN - False Negative 45\n",
      "TP - True Positive 968\n"
     ]
    }
   ],
   "source": [
    "knn_analysis( XX[0], yy[0], 4 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "knn_nneighbors_analysis( XX[1], yy[1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.93      0.92      1041\n",
      "           1       0.95      0.92      0.94      1475\n",
      "\n",
      "   micro avg       0.93      0.93      0.93      2516\n",
      "   macro avg       0.92      0.93      0.93      2516\n",
      "weighted avg       0.93      0.93      0.93      2516\n",
      "\n",
      "Accuracy Rate:  0.9284578696343402\n",
      "Misclassification Rate: 0.0715421303657\n",
      "\n",
      "TP - True Negative 972\n",
      "FP - False Positive 69\n",
      "FN - False Negative 111\n",
      "TP - True Positive 1364\n"
     ]
    }
   ],
   "source": [
    "knn_analysis( XX[1], yy[1], 10 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "knn_nneighbors_analysis( XX[2], yy[2] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.92      0.90      1046\n",
      "           1       0.97      0.95      0.96      2476\n",
      "\n",
      "   micro avg       0.94      0.94      0.94      3522\n",
      "   macro avg       0.92      0.93      0.93      3522\n",
      "weighted avg       0.94      0.94      0.94      3522\n",
      "\n",
      "Accuracy Rate:  0.9403747870528109\n",
      "Misclassification Rate: 0.0596252129472\n",
      "\n",
      "TP - True Negative 964\n",
      "FP - False Positive 82\n",
      "FN - False Negative 128\n",
      "TP - True Positive 2348\n"
     ]
    }
   ],
   "source": [
    "knn_analysis( XX[2], yy[2], 7 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model( X, y, name ):\n",
    "    # first we create a reusable logisitic regression and random forest objects\n",
    "    rf_clf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=0)\n",
    "    rf_clf.fit( X, y ) # train object\n",
    "    # save the model to disk\n",
    "    if not os.path.exists( 'models' ):\n",
    "        os.makedirs( 'models' )\n",
    "    str_ = 'models/randomForest_' + name + '_model.sav'\n",
    "    print( \"Saving the model into the disk\\n\" )\n",
    "    joblib.dump( rf_clf, str_ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a model to detect:fakeFollowers\n",
      "Saving the model into the disk\n",
      "\n",
      "Creating a model to detect:spamBots\n",
      "Saving the model into the disk\n",
      "\n",
      "Creating a model to detect:mix\n",
      "Saving the model into the disk\n",
      "\n"
     ]
    }
   ],
   "source": [
    "names = [ 'fakeFollowers', 'spamBots', 'mix' ]\n",
    "for i in range( len( names ) ):\n",
    "    print( \"Creating a model to detect:\" + names[i] )\n",
    "    generate_model( XX[i], yy[i], names[i] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/utils/losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "\n",
      "\n",
      "====Iteration 1  ====\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/1000\n",
      "9389/9389 [==============================] - 1s 103us/sample - loss: 0.2524 - acc: 0.4033\n",
      "Epoch 2/1000\n",
      "9389/9389 [==============================] - 1s 78us/sample - loss: 0.2500 - acc: 0.3350\n",
      "Epoch 3/1000\n",
      "9389/9389 [==============================] - 1s 84us/sample - loss: 0.2500 - acc: 0.3326\n",
      "Epoch 4/1000\n",
      "9389/9389 [==============================] - 1s 73us/sample - loss: 0.2500 - acc: 0.3465\n",
      "Epoch 5/1000\n",
      "9389/9389 [==============================] - 1s 71us/sample - loss: 0.2500 - acc: 0.3395\n",
      "Epoch 6/1000\n",
      "9389/9389 [==============================] - 1s 71us/sample - loss: 0.2500 - acc: 0.3382\n",
      "Epoch 7/1000\n",
      "9389/9389 [==============================] - 1s 72us/sample - loss: 0.2500 - acc: 0.3199\n",
      "Epoch 8/1000\n",
      "9389/9389 [==============================] - 1s 74us/sample - loss: 0.2500 - acc: 0.3751\n",
      "Epoch 9/1000\n",
      "9389/9389 [==============================] - 1s 75us/sample - loss: 0.2500 - acc: 0.4029\n",
      "Epoch 10/1000\n",
      "9389/9389 [==============================] - 1s 75us/sample - loss: 0.2500 - acc: 0.4468\n",
      "Epoch 11/1000\n",
      "9389/9389 [==============================] - 1s 74us/sample - loss: 0.2500 - acc: 0.4550\n",
      "Epoch 12/1000\n",
      "9389/9389 [==============================] - 1s 78us/sample - loss: 0.2500 - acc: 0.4617\n",
      "Epoch 13/1000\n",
      "9389/9389 [==============================] - 1s 81us/sample - loss: 0.2500 - acc: 0.4661\n",
      "Epoch 14/1000\n",
      "9389/9389 [==============================] - 1s 70us/sample - loss: 0.2500 - acc: 0.4586\n",
      "Epoch 15/1000\n",
      "9389/9389 [==============================] - 1s 71us/sample - loss: 0.2500 - acc: 0.4606\n",
      "Epoch 16/1000\n",
      "9389/9389 [==============================] - 1s 70us/sample - loss: 0.2500 - acc: 0.4661\n",
      "Epoch 17/1000\n",
      "9389/9389 [==============================] - 1s 76us/sample - loss: 0.2500 - acc: 0.4564\n",
      "Epoch 18/1000\n",
      "9389/9389 [==============================] - 1s 94us/sample - loss: 0.2500 - acc: 0.4855\n",
      "Epoch 19/1000\n",
      "9389/9389 [==============================] - 1s 73us/sample - loss: 0.2500 - acc: 0.4793\n",
      "Epoch 20/1000\n",
      "9389/9389 [==============================] - 1s 65us/sample - loss: 0.2500 - acc: 0.4716\n",
      "Epoch 21/1000\n",
      "9389/9389 [==============================] - 1s 66us/sample - loss: 0.2500 - acc: 0.4801\n",
      "Epoch 22/1000\n",
      "9389/9389 [==============================] - 1s 63us/sample - loss: 0.2500 - acc: 0.4807\n",
      "Epoch 23/1000\n",
      "9389/9389 [==============================] - 1s 86us/sample - loss: 0.2500 - acc: 0.4866\n",
      "Epoch 24/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4922\n",
      "Epoch 25/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.4960\n",
      "Epoch 26/1000\n",
      "9389/9389 [==============================] - 1s 75us/sample - loss: 0.2500 - acc: 0.4878\n",
      "Epoch 27/1000\n",
      "9389/9389 [==============================] - 1s 90us/sample - loss: 0.2500 - acc: 0.4939\n",
      "Epoch 28/1000\n",
      "9389/9389 [==============================] - 1s 73us/sample - loss: 0.2500 - acc: 0.5036\n",
      "Epoch 29/1000\n",
      "9389/9389 [==============================] - 1s 64us/sample - loss: 0.2500 - acc: 0.4931\n",
      "Epoch 30/1000\n",
      "9389/9389 [==============================] - 1s 68us/sample - loss: 0.2500 - acc: 0.5018\n",
      "Epoch 31/1000\n",
      "9389/9389 [==============================] - 1s 90us/sample - loss: 0.2500 - acc: 0.5018\n",
      "Epoch 32/1000\n",
      "9389/9389 [==============================] - 1s 62us/sample - loss: 0.2500 - acc: 0.4947\n",
      "Epoch 33/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.4880\n",
      "Epoch 34/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4969\n",
      "Epoch 35/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.4985\n",
      "Epoch 36/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4896\n",
      "Epoch 37/1000\n",
      "9389/9389 [==============================] - 1s 62us/sample - loss: 0.2500 - acc: 0.5031\n",
      "Epoch 38/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5027\n",
      "Epoch 39/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.4994\n",
      "Epoch 40/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.4945\n",
      "Epoch 41/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.5027\n",
      "Epoch 42/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.5039\n",
      "Epoch 43/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.4988\n",
      "Epoch 44/1000\n",
      "9389/9389 [==============================] - 1s 62us/sample - loss: 0.2500 - acc: 0.4941\n",
      "Epoch 45/1000\n",
      "9389/9389 [==============================] - 1s 92us/sample - loss: 0.2500 - acc: 0.4989\n",
      "Epoch 46/1000\n",
      "9389/9389 [==============================] - 1s 82us/sample - loss: 0.2500 - acc: 0.5092\n",
      "Epoch 47/1000\n",
      "9389/9389 [==============================] - 1s 69us/sample - loss: 0.2500 - acc: 0.4996\n",
      "Epoch 48/1000\n",
      "9389/9389 [==============================] - 1s 68us/sample - loss: 0.2500 - acc: 0.5069\n",
      "Epoch 49/1000\n",
      "9389/9389 [==============================] - 1s 70us/sample - loss: 0.2500 - acc: 0.4954\n",
      "Epoch 50/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.5002\n",
      "Epoch 51/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5013\n",
      "Epoch 52/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4977\n",
      "Epoch 53/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.5052\n",
      "Epoch 54/1000\n",
      "9389/9389 [==============================] - 1s 62us/sample - loss: 0.2500 - acc: 0.5067\n",
      "Epoch 55/1000\n",
      "9389/9389 [==============================] - 1s 62us/sample - loss: 0.2500 - acc: 0.5035\n",
      "Epoch 56/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.5034\n",
      "Epoch 57/1000\n",
      "9389/9389 [==============================] - 1s 81us/sample - loss: 0.2500 - acc: 0.5139\n",
      "Epoch 58/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.4986\n",
      "Epoch 59/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.4954\n",
      "Epoch 60/1000\n",
      "9389/9389 [==============================] - 1s 64us/sample - loss: 0.2500 - acc: 0.4899\n",
      "Epoch 61/1000\n",
      "9389/9389 [==============================] - 1s 76us/sample - loss: 0.2500 - acc: 0.4900\n",
      "Epoch 62/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5020\n",
      "Epoch 63/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.4998\n",
      "Epoch 64/1000\n",
      "9389/9389 [==============================] - 1s 86us/sample - loss: 0.2500 - acc: 0.4956\n",
      "Epoch 65/1000\n",
      "9389/9389 [==============================] - 1s 94us/sample - loss: 0.2500 - acc: 0.4955\n",
      "Epoch 66/1000\n",
      "9389/9389 [==============================] - 1s 123us/sample - loss: 0.2500 - acc: 0.5006\n",
      "Epoch 67/1000\n",
      "9389/9389 [==============================] - 1s 98us/sample - loss: 0.2500 - acc: 0.4922\n",
      "Epoch 68/1000\n",
      "9389/9389 [==============================] - 1s 64us/sample - loss: 0.2500 - acc: 0.5020\n",
      "Epoch 69/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4904\n",
      "Epoch 70/1000\n",
      "9389/9389 [==============================] - 1s 65us/sample - loss: 0.2500 - acc: 0.4857\n",
      "Epoch 71/1000\n",
      "9389/9389 [==============================] - 1s 80us/sample - loss: 0.2500 - acc: 0.4985\n",
      "Epoch 72/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9389/9389 [==============================] - 1s 66us/sample - loss: 0.2500 - acc: 0.4957\n",
      "Epoch 73/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.5062\n",
      "Epoch 74/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.4958\n",
      "Epoch 75/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4950\n",
      "Epoch 76/1000\n",
      "9389/9389 [==============================] - 1s 64us/sample - loss: 0.2500 - acc: 0.5066\n",
      "Epoch 77/1000\n",
      "9389/9389 [==============================] - 1s 78us/sample - loss: 0.2500 - acc: 0.5068\n",
      "Epoch 78/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.4946\n",
      "Epoch 79/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5086\n",
      "Epoch 80/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5079\n",
      "Epoch 81/1000\n",
      "9389/9389 [==============================] - 1s 67us/sample - loss: 0.2500 - acc: 0.5066\n",
      "Epoch 82/1000\n",
      "9389/9389 [==============================] - 1s 87us/sample - loss: 0.2500 - acc: 0.5042\n",
      "Epoch 83/1000\n",
      "9389/9389 [==============================] - 1s 122us/sample - loss: 0.2500 - acc: 0.5053\n",
      "Epoch 84/1000\n",
      "9389/9389 [==============================] - 1s 65us/sample - loss: 0.2500 - acc: 0.4897\n",
      "Epoch 85/1000\n",
      "9389/9389 [==============================] - 1s 64us/sample - loss: 0.2500 - acc: 0.4910\n",
      "Epoch 86/1000\n",
      "9389/9389 [==============================] - 1s 78us/sample - loss: 0.2500 - acc: 0.5095\n",
      "Epoch 87/1000\n",
      "9389/9389 [==============================] - 1s 65us/sample - loss: 0.2500 - acc: 0.5011\n",
      "Epoch 88/1000\n",
      "9389/9389 [==============================] - 1s 62us/sample - loss: 0.2500 - acc: 0.5058\n",
      "Epoch 89/1000\n",
      "9389/9389 [==============================] - 1s 62us/sample - loss: 0.2500 - acc: 0.4927\n",
      "Epoch 90/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.4994\n",
      "Epoch 91/1000\n",
      "9389/9389 [==============================] - 1s 109us/sample - loss: 0.2500 - acc: 0.5156\n",
      "Epoch 92/1000\n",
      "9389/9389 [==============================] - 1s 98us/sample - loss: 0.2500 - acc: 0.5132\n",
      "Epoch 93/1000\n",
      "9389/9389 [==============================] - 1s 62us/sample - loss: 0.2500 - acc: 0.5041\n",
      "Epoch 94/1000\n",
      "9389/9389 [==============================] - 1s 74us/sample - loss: 0.2500 - acc: 0.5041\n",
      "Epoch 95/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.5003\n",
      "Epoch 96/1000\n",
      "9389/9389 [==============================] - 1s 63us/sample - loss: 0.2500 - acc: 0.4988\n",
      "Epoch 97/1000\n",
      "9389/9389 [==============================] - 1s 90us/sample - loss: 0.2500 - acc: 0.5002\n",
      "Epoch 98/1000\n",
      "9389/9389 [==============================] - 1s 129us/sample - loss: 0.2500 - acc: 0.4976\n",
      "Epoch 99/1000\n",
      "9389/9389 [==============================] - 1s 100us/sample - loss: 0.2500 - acc: 0.4953\n",
      "Epoch 100/1000\n",
      "9389/9389 [==============================] - 1s 92us/sample - loss: 0.2500 - acc: 0.4944\n",
      "Epoch 101/1000\n",
      "9389/9389 [==============================] - 1s 91us/sample - loss: 0.2500 - acc: 0.5032\n",
      "Epoch 102/1000\n",
      "9389/9389 [==============================] - 1s 68us/sample - loss: 0.2500 - acc: 0.5004\n",
      "Epoch 103/1000\n",
      "9389/9389 [==============================] - 1s 116us/sample - loss: 0.2500 - acc: 0.5042\n",
      "Epoch 104/1000\n",
      "9389/9389 [==============================] - 1s 120us/sample - loss: 0.2500 - acc: 0.5019\n",
      "Epoch 105/1000\n",
      "9389/9389 [==============================] - 1s 69us/sample - loss: 0.2500 - acc: 0.5003\n",
      "Epoch 106/1000\n",
      "9389/9389 [==============================] - 1s 70us/sample - loss: 0.2500 - acc: 0.4939\n",
      "Epoch 107/1000\n",
      "9389/9389 [==============================] - 1s 91us/sample - loss: 0.2500 - acc: 0.4955\n",
      "Epoch 108/1000\n",
      "9389/9389 [==============================] - 1s 68us/sample - loss: 0.2500 - acc: 0.5057\n",
      "Epoch 109/1000\n",
      "9389/9389 [==============================] - 1s 133us/sample - loss: 0.2500 - acc: 0.5051\n",
      "Epoch 110/1000\n",
      "9389/9389 [==============================] - 1s 115us/sample - loss: 0.2500 - acc: 0.5092\n",
      "Epoch 111/1000\n",
      "9389/9389 [==============================] - 1s 82us/sample - loss: 0.2500 - acc: 0.4983\n",
      "Epoch 112/1000\n",
      "9389/9389 [==============================] - 1s 74us/sample - loss: 0.2500 - acc: 0.4961\n",
      "Epoch 113/1000\n",
      "9389/9389 [==============================] - 1s 78us/sample - loss: 0.2500 - acc: 0.4993\n",
      "Epoch 114/1000\n",
      "9389/9389 [==============================] - 1s 75us/sample - loss: 0.2500 - acc: 0.4899\n",
      "Epoch 115/1000\n",
      "9389/9389 [==============================] - 1s 80us/sample - loss: 0.2500 - acc: 0.4973\n",
      "Epoch 116/1000\n",
      "9389/9389 [==============================] - 1s 90us/sample - loss: 0.2500 - acc: 0.4888\n",
      "Epoch 117/1000\n",
      "9389/9389 [==============================] - 1s 117us/sample - loss: 0.2500 - acc: 0.5012\n",
      "Epoch 118/1000\n",
      "9389/9389 [==============================] - 1s 108us/sample - loss: 0.2500 - acc: 0.4978\n",
      "Epoch 119/1000\n",
      "9389/9389 [==============================] - 1s 91us/sample - loss: 0.2500 - acc: 0.4952\n",
      "Epoch 120/1000\n",
      "9389/9389 [==============================] - 1s 79us/sample - loss: 0.2500 - acc: 0.4991\n",
      "Epoch 121/1000\n",
      "9389/9389 [==============================] - 1s 86us/sample - loss: 0.2500 - acc: 0.4937\n",
      "Epoch 122/1000\n",
      "9389/9389 [==============================] - 1s 62us/sample - loss: 0.2500 - acc: 0.4999\n",
      "Epoch 123/1000\n",
      "9389/9389 [==============================] - 1s 69us/sample - loss: 0.2500 - acc: 0.4974\n",
      "Epoch 124/1000\n",
      "9389/9389 [==============================] - 1s 64us/sample - loss: 0.2500 - acc: 0.4968\n",
      "Epoch 125/1000\n",
      "9389/9389 [==============================] - 1s 69us/sample - loss: 0.2500 - acc: 0.4995\n",
      "Epoch 126/1000\n",
      "9389/9389 [==============================] - 1s 64us/sample - loss: 0.2500 - acc: 0.4978\n",
      "Epoch 127/1000\n",
      "9389/9389 [==============================] - 1s 80us/sample - loss: 0.2500 - acc: 0.4976\n",
      "Epoch 128/1000\n",
      "9389/9389 [==============================] - 1s 86us/sample - loss: 0.2500 - acc: 0.4973\n",
      "Epoch 129/1000\n",
      "9389/9389 [==============================] - 1s 84us/sample - loss: 0.2500 - acc: 0.4986\n",
      "Epoch 130/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.5018\n",
      "Epoch 131/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.5057\n",
      "Epoch 132/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4925\n",
      "Epoch 133/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.5071\n",
      "Epoch 134/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.4953\n",
      "Epoch 135/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.5006\n",
      "Epoch 136/1000\n",
      "9389/9389 [==============================] - 1s 62us/sample - loss: 0.2500 - acc: 0.4983\n",
      "Epoch 137/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.4987\n",
      "Epoch 138/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.4993\n",
      "Epoch 139/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5006\n",
      "Epoch 140/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.5022\n",
      "Epoch 141/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4985\n",
      "Epoch 142/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.5037\n",
      "Epoch 143/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.4947\n",
      "Epoch 144/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4959\n",
      "Epoch 145/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.5079\n",
      "Epoch 146/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4990\n",
      "Epoch 147/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.5003\n",
      "Epoch 148/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.4980\n",
      "Epoch 149/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.5032\n",
      "Epoch 150/1000\n",
      "9389/9389 [==============================] - 1s 57us/sample - loss: 0.2500 - acc: 0.5124\n",
      "Epoch 151/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.5068\n",
      "Epoch 152/1000\n",
      "9389/9389 [==============================] - 1s 63us/sample - loss: 0.2500 - acc: 0.5024\n",
      "Epoch 153/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5116\n",
      "Epoch 154/1000\n",
      "9389/9389 [==============================] - 1s 62us/sample - loss: 0.2500 - acc: 0.5017\n",
      "Epoch 155/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5004\n",
      "Epoch 156/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4991\n",
      "Epoch 157/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5038\n",
      "Epoch 158/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4991\n",
      "Epoch 159/1000\n",
      "9389/9389 [==============================] - 1s 64us/sample - loss: 0.2500 - acc: 0.4923\n",
      "Epoch 160/1000\n",
      "9389/9389 [==============================] - 1s 63us/sample - loss: 0.2500 - acc: 0.4999\n",
      "Epoch 161/1000\n",
      "9389/9389 [==============================] - 1s 64us/sample - loss: 0.2500 - acc: 0.5080\n",
      "Epoch 162/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5025\n",
      "Epoch 163/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4997\n",
      "Epoch 164/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4948\n",
      "Epoch 165/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5083\n",
      "Epoch 166/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5063\n",
      "Epoch 167/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4988\n",
      "Epoch 168/1000\n",
      "9389/9389 [==============================] - 1s 64us/sample - loss: 0.2500 - acc: 0.5015\n",
      "Epoch 169/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.4983\n",
      "Epoch 170/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.4981\n",
      "Epoch 171/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5064\n",
      "Epoch 172/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.5025\n",
      "Epoch 173/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5018\n",
      "Epoch 174/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5048\n",
      "Epoch 175/1000\n",
      "9389/9389 [==============================] - 1s 64us/sample - loss: 0.2500 - acc: 0.5039\n",
      "Epoch 176/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5011\n",
      "Epoch 177/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.5110\n",
      "Epoch 178/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.5002\n",
      "Epoch 179/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.4993\n",
      "Epoch 180/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4960\n",
      "Epoch 181/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4990\n",
      "Epoch 182/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.5120\n",
      "Epoch 183/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4955\n",
      "Epoch 184/1000\n",
      "9389/9389 [==============================] - 1s 62us/sample - loss: 0.2500 - acc: 0.5058\n",
      "Epoch 185/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.4921\n",
      "Epoch 186/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4971\n",
      "Epoch 187/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.4990\n",
      "Epoch 188/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.4974\n",
      "Epoch 189/1000\n",
      "9389/9389 [==============================] - 1s 63us/sample - loss: 0.2500 - acc: 0.5039\n",
      "Epoch 190/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5034\n",
      "Epoch 191/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.5094\n",
      "Epoch 192/1000\n",
      "9389/9389 [==============================] - 1s 57us/sample - loss: 0.2500 - acc: 0.5025\n",
      "Epoch 193/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.4977\n",
      "Epoch 194/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.5048\n",
      "Epoch 195/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5086\n",
      "Epoch 196/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.5030\n",
      "Epoch 197/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.4968\n",
      "Epoch 198/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5009\n",
      "Epoch 199/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.5032\n",
      "Epoch 200/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4987\n",
      "Epoch 201/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4977\n",
      "Epoch 202/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.5110\n",
      "Epoch 203/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.5017\n",
      "Epoch 204/1000\n",
      "9389/9389 [==============================] - 1s 63us/sample - loss: 0.2500 - acc: 0.5029\n",
      "Epoch 205/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.4955\n",
      "Epoch 206/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.4990\n",
      "Epoch 207/1000\n",
      "9389/9389 [==============================] - 1s 62us/sample - loss: 0.2500 - acc: 0.5037\n",
      "Epoch 208/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.4906\n",
      "Epoch 209/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.4987\n",
      "Epoch 210/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5080\n",
      "Epoch 211/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4997\n",
      "Epoch 212/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5021\n",
      "Epoch 213/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4995\n",
      "Epoch 214/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.4927\n",
      "Epoch 215/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5036\n",
      "Epoch 216/1000\n",
      "9389/9389 [==============================] - 1s 64us/sample - loss: 0.2500 - acc: 0.4897\n",
      "Epoch 217/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4973\n",
      "Epoch 218/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4913\n",
      "Epoch 219/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5042\n",
      "Epoch 220/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.5040\n",
      "Epoch 221/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.5017\n",
      "Epoch 222/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.5020\n",
      "Epoch 223/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.4954\n",
      "Epoch 224/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.4929\n",
      "Epoch 225/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.5048\n",
      "Epoch 226/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.5015\n",
      "Epoch 227/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.5015\n",
      "Epoch 228/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.4993\n",
      "Epoch 229/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4947\n",
      "Epoch 230/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.4991\n",
      "Epoch 231/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5007\n",
      "Epoch 232/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.5053\n",
      "Epoch 233/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.5053\n",
      "Epoch 234/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.4934\n",
      "Epoch 235/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5008\n",
      "Epoch 236/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4946\n",
      "Epoch 237/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.4987\n",
      "Epoch 238/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4963\n",
      "Epoch 239/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.4989\n",
      "Epoch 240/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4998\n",
      "Epoch 241/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.5074\n",
      "Epoch 242/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.4979\n",
      "Epoch 243/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.5037\n",
      "Epoch 244/1000\n",
      "9389/9389 [==============================] - 1s 65us/sample - loss: 0.2500 - acc: 0.4922\n",
      "Epoch 245/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5044\n",
      "Epoch 246/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.4978\n",
      "Epoch 247/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.4971\n",
      "Epoch 248/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.5026\n",
      "Epoch 249/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.4960\n",
      "Epoch 250/1000\n",
      "9389/9389 [==============================] - 1s 62us/sample - loss: 0.2500 - acc: 0.5048\n",
      "Epoch 251/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.5009\n",
      "Epoch 252/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4996\n",
      "Epoch 253/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.4957\n",
      "Epoch 254/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5041\n",
      "Epoch 255/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.5093\n",
      "Epoch 256/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4974\n",
      "Epoch 257/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4982\n",
      "Epoch 258/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.4988\n",
      "Epoch 259/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4991\n",
      "Epoch 260/1000\n",
      "9389/9389 [==============================] - 1s 62us/sample - loss: 0.2500 - acc: 0.4965\n",
      "Epoch 261/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.4962\n",
      "Epoch 262/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4942\n",
      "Epoch 263/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4920\n",
      "Epoch 264/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.5062\n",
      "Epoch 265/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5146\n",
      "Epoch 266/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4942\n",
      "Epoch 267/1000\n",
      "9389/9389 [==============================] - 1s 62us/sample - loss: 0.2500 - acc: 0.4981\n",
      "Epoch 268/1000\n",
      "9389/9389 [==============================] - 1s 62us/sample - loss: 0.2500 - acc: 0.4976\n",
      "Epoch 269/1000\n",
      "9389/9389 [==============================] - 1s 63us/sample - loss: 0.2500 - acc: 0.4915\n",
      "Epoch 270/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.5066\n",
      "Epoch 271/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.5004\n",
      "Epoch 272/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.4960\n",
      "Epoch 273/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.4985\n",
      "Epoch 274/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5024\n",
      "Epoch 275/1000\n",
      "9389/9389 [==============================] - 1s 63us/sample - loss: 0.2500 - acc: 0.5067\n",
      "Epoch 276/1000\n",
      "9389/9389 [==============================] - 1s 65us/sample - loss: 0.2500 - acc: 0.5044\n",
      "Epoch 277/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.4985\n",
      "Epoch 278/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5012\n",
      "Epoch 279/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4995\n",
      "Epoch 280/1000\n",
      "9389/9389 [==============================] - ETA: 0s - loss: 0.2500 - acc: 0.508 - 1s 60us/sample - loss: 0.2500 - acc: 0.5081\n",
      "Epoch 281/1000\n",
      "9389/9389 [==============================] - 1s 64us/sample - loss: 0.2500 - acc: 0.4954\n",
      "Epoch 282/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.5015\n",
      "Epoch 283/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.5088\n",
      "Epoch 284/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.5046\n",
      "Epoch 285/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5039\n",
      "Epoch 286/1000\n",
      "9389/9389 [==============================] - 1s 62us/sample - loss: 0.2500 - acc: 0.4990\n",
      "Epoch 287/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.4961\n",
      "Epoch 288/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.4954\n",
      "Epoch 289/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.4946\n",
      "Epoch 290/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.5045\n",
      "Epoch 291/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.4985\n",
      "Epoch 292/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.5025\n",
      "Epoch 293/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.4994\n",
      "Epoch 294/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4922\n",
      "Epoch 295/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5050\n",
      "Epoch 296/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.4941\n",
      "Epoch 297/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.4974\n",
      "Epoch 298/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.5011\n",
      "Epoch 299/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.4945\n",
      "Epoch 300/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.5032\n",
      "Epoch 301/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.5051\n",
      "Epoch 302/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.4920\n",
      "Epoch 303/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.5034\n",
      "Epoch 304/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.5088\n",
      "Epoch 305/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.5021\n",
      "Epoch 306/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.4940\n",
      "Epoch 307/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.5064\n",
      "Epoch 308/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.5001\n",
      "Epoch 309/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.5094\n",
      "Epoch 310/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5076\n",
      "Epoch 311/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.5026\n",
      "Epoch 312/1000\n",
      "9389/9389 [==============================] - 1s 64us/sample - loss: 0.2500 - acc: 0.4990\n",
      "Epoch 313/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.5066\n",
      "Epoch 314/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.4966\n",
      "Epoch 315/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5087\n",
      "Epoch 316/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.4991\n",
      "Epoch 317/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.5025\n",
      "Epoch 318/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.5007\n",
      "Epoch 319/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.5056\n",
      "Epoch 320/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4964\n",
      "Epoch 321/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4991\n",
      "Epoch 322/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4961\n",
      "Epoch 323/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.5020\n",
      "Epoch 324/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.4924\n",
      "Epoch 325/1000\n",
      "9389/9389 [==============================] - 1s 62us/sample - loss: 0.2500 - acc: 0.5023\n",
      "Epoch 326/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4915\n",
      "Epoch 327/1000\n",
      "9389/9389 [==============================] - 1s 72us/sample - loss: 0.2500 - acc: 0.5081\n",
      "Epoch 328/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.5012\n",
      "Epoch 329/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.4981\n",
      "Epoch 330/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.5028\n",
      "Epoch 331/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.4989\n",
      "Epoch 332/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.4977\n",
      "Epoch 333/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.5022\n",
      "Epoch 334/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.4987\n",
      "Epoch 335/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.4964\n",
      "Epoch 336/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.4971\n",
      "Epoch 337/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.5001\n",
      "Epoch 338/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4966\n",
      "Epoch 339/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.4958\n",
      "Epoch 340/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4981\n",
      "Epoch 341/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.5070\n",
      "Epoch 342/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.4981\n",
      "Epoch 343/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.5022\n",
      "Epoch 344/1000\n",
      "9389/9389 [==============================] - 1s 62us/sample - loss: 0.2500 - acc: 0.5009\n",
      "Epoch 345/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.5035\n",
      "Epoch 346/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.4997\n",
      "Epoch 347/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4997\n",
      "Epoch 348/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.4989\n",
      "Epoch 349/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.4978\n",
      "Epoch 350/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.4940\n",
      "Epoch 351/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.5052\n",
      "Epoch 352/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.4947\n",
      "Epoch 353/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5029\n",
      "Epoch 354/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.4976\n",
      "Epoch 355/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.4981\n",
      "Epoch 356/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5021\n",
      "Epoch 357/1000\n",
      "9389/9389 [==============================] - 1s 62us/sample - loss: 0.2500 - acc: 0.5005TA: 0s - loss: 0.2500 - acc:\n",
      "Epoch 358/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.5062\n",
      "Epoch 359/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.4927\n",
      "Epoch 360/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.4954\n",
      "Epoch 361/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.5106\n",
      "Epoch 362/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5003\n",
      "Epoch 363/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5057\n",
      "Epoch 364/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.4936\n",
      "Epoch 365/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.5002\n",
      "Epoch 366/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.4889\n",
      "Epoch 367/1000\n",
      "9389/9389 [==============================] - 1s 62us/sample - loss: 0.2500 - acc: 0.5009\n",
      "Epoch 368/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5020\n",
      "Epoch 369/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.5072\n",
      "Epoch 370/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5037\n",
      "Epoch 371/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5024\n",
      "Epoch 372/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4952\n",
      "Epoch 373/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4950\n",
      "Epoch 374/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.5062\n",
      "Epoch 375/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.5020\n",
      "Epoch 376/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.5020\n",
      "Epoch 377/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.5062\n",
      "Epoch 378/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.5037\n",
      "Epoch 379/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.4896\n",
      "Epoch 380/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.5021\n",
      "Epoch 381/1000\n",
      "9389/9389 [==============================] - 1s 62us/sample - loss: 0.2500 - acc: 0.4995\n",
      "Epoch 382/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4981\n",
      "Epoch 383/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.5057\n",
      "Epoch 384/1000\n",
      "9389/9389 [==============================] - 1s 64us/sample - loss: 0.2500 - acc: 0.4936\n",
      "Epoch 385/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.4941\n",
      "Epoch 386/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5073\n",
      "Epoch 387/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4916\n",
      "Epoch 388/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5014\n",
      "Epoch 389/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5019\n",
      "Epoch 390/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4903\n",
      "Epoch 391/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4998\n",
      "Epoch 392/1000\n",
      "9389/9389 [==============================] - 1s 62us/sample - loss: 0.2500 - acc: 0.5024\n",
      "Epoch 393/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5062\n",
      "Epoch 394/1000\n",
      "9389/9389 [==============================] - 1s 62us/sample - loss: 0.2500 - acc: 0.4976\n",
      "Epoch 395/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.5030\n",
      "Epoch 396/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.5067\n",
      "Epoch 397/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.4947\n",
      "Epoch 398/1000\n",
      "9389/9389 [==============================] - 1s 62us/sample - loss: 0.2500 - acc: 0.5007\n",
      "Epoch 399/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.4930\n",
      "Epoch 400/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5102\n",
      "Epoch 401/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.4998\n",
      "Epoch 402/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5017\n",
      "Epoch 403/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.5015\n",
      "Epoch 404/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5087\n",
      "Epoch 405/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.5013\n",
      "Epoch 406/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4994\n",
      "Epoch 407/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.5023A: 0s - loss: 0.2500 - acc\n",
      "Epoch 408/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4964\n",
      "Epoch 409/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.5024\n",
      "Epoch 410/1000\n",
      "9389/9389 [==============================] - 1s 62us/sample - loss: 0.2500 - acc: 0.5041\n",
      "Epoch 411/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.5057\n",
      "Epoch 412/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5039\n",
      "Epoch 413/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.4973\n",
      "Epoch 414/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.5017\n",
      "Epoch 415/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.4938\n",
      "Epoch 416/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.4993\n",
      "Epoch 417/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.4978\n",
      "Epoch 418/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.5055\n",
      "Epoch 419/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.5040\n",
      "Epoch 420/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4980\n",
      "Epoch 421/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5027\n",
      "Epoch 422/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.5066\n",
      "Epoch 423/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4948\n",
      "Epoch 424/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.4997\n",
      "Epoch 425/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.4953\n",
      "Epoch 426/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.5095\n",
      "Epoch 427/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.4991\n",
      "Epoch 428/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5009\n",
      "Epoch 429/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.5023\n",
      "Epoch 430/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.4986\n",
      "Epoch 431/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.4999\n",
      "Epoch 432/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.4937\n",
      "Epoch 433/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.4998\n",
      "Epoch 434/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.5075\n",
      "Epoch 435/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.4974\n",
      "Epoch 436/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.5086\n",
      "Epoch 437/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5018\n",
      "Epoch 438/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.5005\n",
      "Epoch 439/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4938\n",
      "Epoch 440/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.4980\n",
      "Epoch 441/1000\n",
      "9389/9389 [==============================] - 1s 62us/sample - loss: 0.2500 - acc: 0.5063\n",
      "Epoch 442/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.4985\n",
      "Epoch 443/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.5004\n",
      "Epoch 444/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.4987\n",
      "Epoch 445/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.4934\n",
      "Epoch 446/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4997\n",
      "Epoch 447/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.4944\n",
      "Epoch 448/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.5014\n",
      "Epoch 449/1000\n",
      "9389/9389 [==============================] - 1s 57us/sample - loss: 0.2500 - acc: 0.5001\n",
      "Epoch 450/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.4968\n",
      "Epoch 451/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5069\n",
      "Epoch 452/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5035\n",
      "Epoch 453/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.4974\n",
      "Epoch 454/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.5044\n",
      "Epoch 455/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4978\n",
      "Epoch 456/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5101\n",
      "Epoch 457/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4939\n",
      "Epoch 458/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4980\n",
      "Epoch 459/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.4991\n",
      "Epoch 460/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.5013\n",
      "Epoch 461/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.4961\n",
      "Epoch 462/1000\n",
      "9389/9389 [==============================] - 1s 62us/sample - loss: 0.2500 - acc: 0.5076\n",
      "Epoch 463/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.4976\n",
      "Epoch 464/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.5071\n",
      "Epoch 465/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.5031\n",
      "Epoch 466/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4944\n",
      "Epoch 467/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.4932\n",
      "Epoch 468/1000\n",
      "9389/9389 [==============================] - 1s 62us/sample - loss: 0.2500 - acc: 0.5013\n",
      "Epoch 469/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5019\n",
      "Epoch 470/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4991\n",
      "Epoch 471/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.5050\n",
      "Epoch 472/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.5074\n",
      "Epoch 473/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5047\n",
      "Epoch 474/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.5086\n",
      "Epoch 475/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.4914\n",
      "Epoch 476/1000\n",
      "9389/9389 [==============================] - 1s 62us/sample - loss: 0.2500 - acc: 0.4985\n",
      "Epoch 477/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4983\n",
      "Epoch 478/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.4994\n",
      "Epoch 479/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.4925\n",
      "Epoch 480/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5056\n",
      "Epoch 481/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5055\n",
      "Epoch 482/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.4955\n",
      "Epoch 483/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.4976\n",
      "Epoch 484/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.5059\n",
      "Epoch 485/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4942\n",
      "Epoch 486/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5001\n",
      "Epoch 487/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.4969\n",
      "Epoch 488/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4900\n",
      "Epoch 489/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.5048\n",
      "Epoch 490/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.4906\n",
      "Epoch 491/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.5020\n",
      "Epoch 492/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4997\n",
      "Epoch 493/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.5034\n",
      "Epoch 494/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.5097\n",
      "Epoch 495/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4954\n",
      "Epoch 496/1000\n",
      "9389/9389 [==============================] - 1s 62us/sample - loss: 0.2500 - acc: 0.5040\n",
      "Epoch 497/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5011\n",
      "Epoch 498/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.5041\n",
      "Epoch 499/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5011\n",
      "Epoch 500/1000\n",
      "9389/9389 [==============================] - 1s 62us/sample - loss: 0.2500 - acc: 0.5012\n",
      "Epoch 501/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.5022\n",
      "Epoch 502/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4943\n",
      "Epoch 503/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.5059\n",
      "Epoch 504/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4993\n",
      "Epoch 505/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.4978\n",
      "Epoch 506/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.4980\n",
      "Epoch 507/1000\n",
      "9389/9389 [==============================] - 1s 62us/sample - loss: 0.2500 - acc: 0.5009\n",
      "Epoch 508/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5018\n",
      "Epoch 509/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.4988\n",
      "Epoch 510/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.5004\n",
      "Epoch 511/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4982\n",
      "Epoch 512/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.5017\n",
      "Epoch 513/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4955\n",
      "Epoch 514/1000\n",
      "9389/9389 [==============================] - 1s 64us/sample - loss: 0.2500 - acc: 0.4988\n",
      "Epoch 515/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.5009\n",
      "Epoch 516/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5059\n",
      "Epoch 517/1000\n",
      "9389/9389 [==============================] - 1s 62us/sample - loss: 0.2500 - acc: 0.5013\n",
      "Epoch 518/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.4934\n",
      "Epoch 519/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.4913\n",
      "Epoch 520/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.4965\n",
      "Epoch 521/1000\n",
      "9389/9389 [==============================] - 1s 62us/sample - loss: 0.2500 - acc: 0.5009\n",
      "Epoch 522/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4952\n",
      "Epoch 523/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5023\n",
      "Epoch 524/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.5025\n",
      "Epoch 525/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.4976\n",
      "Epoch 526/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4982\n",
      "Epoch 527/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.4930\n",
      "Epoch 528/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.5087\n",
      "Epoch 529/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.4976\n",
      "Epoch 530/1000\n",
      "9389/9389 [==============================] - 1s 62us/sample - loss: 0.2500 - acc: 0.5061\n",
      "Epoch 531/1000\n",
      "9389/9389 [==============================] - 1s 62us/sample - loss: 0.2500 - acc: 0.5060\n",
      "Epoch 532/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.4960\n",
      "Epoch 533/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.4995\n",
      "Epoch 534/1000\n",
      "9389/9389 [==============================] - 1s 63us/sample - loss: 0.2500 - acc: 0.4998\n",
      "Epoch 535/1000\n",
      "9389/9389 [==============================] - 1s 62us/sample - loss: 0.2500 - acc: 0.5028\n",
      "Epoch 536/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.4982\n",
      "Epoch 537/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4900\n",
      "Epoch 538/1000\n",
      "9389/9389 [==============================] - 1s 63us/sample - loss: 0.2500 - acc: 0.5036\n",
      "Epoch 539/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4946\n",
      "Epoch 540/1000\n",
      "9389/9389 [==============================] - 1s 72us/sample - loss: 0.2500 - acc: 0.5005\n",
      "Epoch 541/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9389/9389 [==============================] - 1s 63us/sample - loss: 0.2500 - acc: 0.4952\n",
      "Epoch 542/1000\n",
      "9389/9389 [==============================] - 1s 63us/sample - loss: 0.2500 - acc: 0.5089\n",
      "Epoch 543/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.5006\n",
      "Epoch 544/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.5023\n",
      "Epoch 545/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.4917\n",
      "Epoch 546/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5021\n",
      "Epoch 547/1000\n",
      "9389/9389 [==============================] - 1s 62us/sample - loss: 0.2500 - acc: 0.4973\n",
      "Epoch 548/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4985\n",
      "Epoch 549/1000\n",
      "9389/9389 [==============================] - 1s 62us/sample - loss: 0.2500 - acc: 0.4979\n",
      "Epoch 550/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.4930\n",
      "Epoch 551/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4961\n",
      "Epoch 552/1000\n",
      "9389/9389 [==============================] - 1s 62us/sample - loss: 0.2500 - acc: 0.4838\n",
      "Epoch 553/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5080\n",
      "Epoch 554/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.5007\n",
      "Epoch 555/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.5005\n",
      "Epoch 556/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.4974\n",
      "Epoch 557/1000\n",
      "9389/9389 [==============================] - ETA: 0s - loss: 0.2500 - acc: 0.506 - 1s 60us/sample - loss: 0.2500 - acc: 0.5040\n",
      "Epoch 558/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4968\n",
      "Epoch 559/1000\n",
      "9389/9389 [==============================] - 1s 62us/sample - loss: 0.2500 - acc: 0.4964\n",
      "Epoch 560/1000\n",
      "9389/9389 [==============================] - 1s 62us/sample - loss: 0.2500 - acc: 0.4874\n",
      "Epoch 561/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.5007\n",
      "Epoch 562/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5083\n",
      "Epoch 563/1000\n",
      "9389/9389 [==============================] - 1s 64us/sample - loss: 0.2500 - acc: 0.5001\n",
      "Epoch 564/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.4971\n",
      "Epoch 565/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5037\n",
      "Epoch 566/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5048\n",
      "Epoch 567/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4899\n",
      "Epoch 568/1000\n",
      "9389/9389 [==============================] - 1s 62us/sample - loss: 0.2500 - acc: 0.5031\n",
      "Epoch 569/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.5014\n",
      "Epoch 570/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.5079\n",
      "Epoch 571/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.4952\n",
      "Epoch 572/1000\n",
      "9389/9389 [==============================] - 1s 64us/sample - loss: 0.2500 - acc: 0.4999\n",
      "Epoch 573/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.5035\n",
      "Epoch 574/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.5062\n",
      "Epoch 575/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.4961\n",
      "Epoch 576/1000\n",
      "9389/9389 [==============================] - 1s 63us/sample - loss: 0.2500 - acc: 0.5031\n",
      "Epoch 577/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4961\n",
      "Epoch 578/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4966\n",
      "Epoch 579/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4987\n",
      "Epoch 580/1000\n",
      "9389/9389 [==============================] - 1s 62us/sample - loss: 0.2500 - acc: 0.5023\n",
      "Epoch 581/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5007\n",
      "Epoch 582/1000\n",
      "9389/9389 [==============================] - 1s 62us/sample - loss: 0.2500 - acc: 0.4961\n",
      "Epoch 583/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5028\n",
      "Epoch 584/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5042\n",
      "Epoch 585/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.4957\n",
      "Epoch 586/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5042\n",
      "Epoch 587/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4975\n",
      "Epoch 588/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4958\n",
      "Epoch 589/1000\n",
      "9389/9389 [==============================] - 1s 62us/sample - loss: 0.2500 - acc: 0.5048\n",
      "Epoch 590/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.5040\n",
      "Epoch 591/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.4977\n",
      "Epoch 592/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.5022\n",
      "Epoch 593/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4948\n",
      "Epoch 594/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4922\n",
      "Epoch 595/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4958\n",
      "Epoch 596/1000\n",
      "9389/9389 [==============================] - 1s 62us/sample - loss: 0.2500 - acc: 0.4964\n",
      "Epoch 597/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.5041\n",
      "Epoch 598/1000\n",
      "9389/9389 [==============================] - 1s 57us/sample - loss: 0.2500 - acc: 0.5093\n",
      "Epoch 599/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4913\n",
      "Epoch 600/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.4900\n",
      "Epoch 601/1000\n",
      "9389/9389 [==============================] - 1s 66us/sample - loss: 0.2500 - acc: 0.5017\n",
      "Epoch 602/1000\n",
      "9389/9389 [==============================] - 1s 114us/sample - loss: 0.2500 - acc: 0.5039\n",
      "Epoch 603/1000\n",
      "9389/9389 [==============================] - 1s 85us/sample - loss: 0.2500 - acc: 0.4892\n",
      "Epoch 604/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.5023\n",
      "Epoch 605/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.5002\n",
      "Epoch 606/1000\n",
      "9389/9389 [==============================] - 1s 62us/sample - loss: 0.2500 - acc: 0.5004\n",
      "Epoch 607/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4963\n",
      "Epoch 608/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.5011\n",
      "Epoch 609/1000\n",
      "9389/9389 [==============================] - 1s 68us/sample - loss: 0.2500 - acc: 0.4940\n",
      "Epoch 610/1000\n",
      "9389/9389 [==============================] - 1s 62us/sample - loss: 0.2500 - acc: 0.4986\n",
      "Epoch 611/1000\n",
      "9389/9389 [==============================] - 1s 66us/sample - loss: 0.2500 - acc: 0.5018\n",
      "Epoch 612/1000\n",
      "9389/9389 [==============================] - 1s 62us/sample - loss: 0.2500 - acc: 0.4936\n",
      "Epoch 613/1000\n",
      "9389/9389 [==============================] - 1s 65us/sample - loss: 0.2500 - acc: 0.4993\n",
      "Epoch 614/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4926\n",
      "Epoch 615/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.5132\n",
      "Epoch 616/1000\n",
      "9389/9389 [==============================] - 1s 63us/sample - loss: 0.2500 - acc: 0.5059\n",
      "Epoch 617/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.5006\n",
      "Epoch 618/1000\n",
      "9389/9389 [==============================] - 1s 62us/sample - loss: 0.2500 - acc: 0.5018\n",
      "Epoch 619/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9389/9389 [==============================] - 1s 62us/sample - loss: 0.2500 - acc: 0.4971\n",
      "Epoch 620/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.4881\n",
      "Epoch 621/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.5009\n",
      "Epoch 622/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.5043\n",
      "Epoch 623/1000\n",
      "9389/9389 [==============================] - 1s 64us/sample - loss: 0.2500 - acc: 0.4978\n",
      "Epoch 624/1000\n",
      "9389/9389 [==============================] - 1s 62us/sample - loss: 0.2500 - acc: 0.4848\n",
      "Epoch 625/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.5066\n",
      "Epoch 626/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.4968\n",
      "Epoch 627/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.4994\n",
      "Epoch 628/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4986\n",
      "Epoch 629/1000\n",
      "9389/9389 [==============================] - 1s 62us/sample - loss: 0.2500 - acc: 0.4941\n",
      "Epoch 630/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.5041\n",
      "Epoch 631/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4932\n",
      "Epoch 632/1000\n",
      "9389/9389 [==============================] - 1s 62us/sample - loss: 0.2500 - acc: 0.5017\n",
      "Epoch 633/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5019\n",
      "Epoch 634/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.5019\n",
      "Epoch 635/1000\n",
      "9389/9389 [==============================] - 1s 63us/sample - loss: 0.2500 - acc: 0.4970\n",
      "Epoch 636/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5071\n",
      "Epoch 637/1000\n",
      "9389/9389 [==============================] - 1s 65us/sample - loss: 0.2500 - acc: 0.5034\n",
      "Epoch 638/1000\n",
      "9389/9389 [==============================] - 1s 62us/sample - loss: 0.2500 - acc: 0.5004\n",
      "Epoch 639/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.4969\n",
      "Epoch 640/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.4977\n",
      "Epoch 641/1000\n",
      "9389/9389 [==============================] - 1s 66us/sample - loss: 0.2500 - acc: 0.4972\n",
      "Epoch 642/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.4980\n",
      "Epoch 643/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4960\n",
      "Epoch 644/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.5037\n",
      "Epoch 645/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4977\n",
      "Epoch 646/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.4961\n",
      "Epoch 647/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.4937\n",
      "Epoch 648/1000\n",
      "9389/9389 [==============================] - 1s 62us/sample - loss: 0.2500 - acc: 0.5006\n",
      "Epoch 649/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.4959\n",
      "Epoch 650/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.4981\n",
      "Epoch 651/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.5054\n",
      "Epoch 652/1000\n",
      "9389/9389 [==============================] - 1s 62us/sample - loss: 0.2500 - acc: 0.5056\n",
      "Epoch 653/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.5020\n",
      "Epoch 654/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.4988\n",
      "Epoch 655/1000\n",
      "9389/9389 [==============================] - 1s 70us/sample - loss: 0.2500 - acc: 0.5093\n",
      "Epoch 656/1000\n",
      "9389/9389 [==============================] - 1s 72us/sample - loss: 0.2500 - acc: 0.5014\n",
      "Epoch 657/1000\n",
      "9389/9389 [==============================] - 1s 71us/sample - loss: 0.2500 - acc: 0.4921\n",
      "Epoch 658/1000\n",
      "9389/9389 [==============================] - 1s 68us/sample - loss: 0.2500 - acc: 0.5063\n",
      "Epoch 659/1000\n",
      "9389/9389 [==============================] - 1s 68us/sample - loss: 0.2500 - acc: 0.5007\n",
      "Epoch 660/1000\n",
      "9389/9389 [==============================] - 1s 69us/sample - loss: 0.2500 - acc: 0.4987\n",
      "Epoch 661/1000\n",
      "9389/9389 [==============================] - 1s 68us/sample - loss: 0.2500 - acc: 0.5079\n",
      "Epoch 662/1000\n",
      "9389/9389 [==============================] - 1s 67us/sample - loss: 0.2500 - acc: 0.5014\n",
      "Epoch 663/1000\n",
      "9389/9389 [==============================] - 1s 65us/sample - loss: 0.2500 - acc: 0.4972\n",
      "Epoch 664/1000\n",
      "9389/9389 [==============================] - 1s 65us/sample - loss: 0.2500 - acc: 0.5061\n",
      "Epoch 665/1000\n",
      "9389/9389 [==============================] - 1s 64us/sample - loss: 0.2500 - acc: 0.5006\n",
      "Epoch 666/1000\n",
      "9389/9389 [==============================] - 1s 65us/sample - loss: 0.2500 - acc: 0.5015\n",
      "Epoch 667/1000\n",
      "9389/9389 [==============================] - 1s 64us/sample - loss: 0.2500 - acc: 0.5090\n",
      "Epoch 668/1000\n",
      "9389/9389 [==============================] - 1s 62us/sample - loss: 0.2500 - acc: 0.4923\n",
      "Epoch 669/1000\n",
      "9389/9389 [==============================] - 1s 63us/sample - loss: 0.2500 - acc: 0.5004\n",
      "Epoch 670/1000\n",
      "9389/9389 [==============================] - 1s 80us/sample - loss: 0.2500 - acc: 0.5086\n",
      "Epoch 671/1000\n",
      "9389/9389 [==============================] - 1s 113us/sample - loss: 0.2500 - acc: 0.5071\n",
      "Epoch 672/1000\n",
      "9389/9389 [==============================] - 1s 99us/sample - loss: 0.2500 - acc: 0.5058\n",
      "Epoch 673/1000\n",
      "9389/9389 [==============================] - 1s 66us/sample - loss: 0.2500 - acc: 0.5031\n",
      "Epoch 674/1000\n",
      "9389/9389 [==============================] - 1s 70us/sample - loss: 0.2500 - acc: 0.5031\n",
      "Epoch 675/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.4973\n",
      "Epoch 676/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5018\n",
      "Epoch 677/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.5019\n",
      "Epoch 678/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.5073\n",
      "Epoch 679/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.5072\n",
      "Epoch 680/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.5061\n",
      "Epoch 681/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.4932\n",
      "Epoch 682/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5002\n",
      "Epoch 683/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.4969\n",
      "Epoch 684/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5019\n",
      "Epoch 685/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.5002\n",
      "Epoch 686/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5024\n",
      "Epoch 687/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.4965\n",
      "Epoch 688/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.4941\n",
      "Epoch 689/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.4975\n",
      "Epoch 690/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.4993\n",
      "Epoch 691/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4976\n",
      "Epoch 692/1000\n",
      "9389/9389 [==============================] - 1s 57us/sample - loss: 0.2500 - acc: 0.4934\n",
      "Epoch 693/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.5095\n",
      "Epoch 694/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.5029\n",
      "Epoch 695/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5020\n",
      "Epoch 696/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.5039\n",
      "Epoch 697/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.5015\n",
      "Epoch 698/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.5003\n",
      "Epoch 699/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.4965\n",
      "Epoch 700/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.4961\n",
      "Epoch 701/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.4925\n",
      "Epoch 702/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5113\n",
      "Epoch 703/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.5012\n",
      "Epoch 704/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.4975\n",
      "Epoch 705/1000\n",
      "9389/9389 [==============================] - 1s 57us/sample - loss: 0.2500 - acc: 0.4948\n",
      "Epoch 706/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.4948\n",
      "Epoch 707/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.5026\n",
      "Epoch 708/1000\n",
      "9389/9389 [==============================] - 1s 57us/sample - loss: 0.2500 - acc: 0.4975\n",
      "Epoch 709/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4996\n",
      "Epoch 710/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5096\n",
      "Epoch 711/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5023\n",
      "Epoch 712/1000\n",
      "9389/9389 [==============================] - 1s 63us/sample - loss: 0.2500 - acc: 0.4995\n",
      "Epoch 713/1000\n",
      "9389/9389 [==============================] - 1s 66us/sample - loss: 0.2500 - acc: 0.5054\n",
      "Epoch 714/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.5046\n",
      "Epoch 715/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.4972\n",
      "Epoch 716/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4973\n",
      "Epoch 717/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5100\n",
      "Epoch 718/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4913\n",
      "Epoch 719/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.4970\n",
      "Epoch 720/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5055\n",
      "Epoch 721/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.4999\n",
      "Epoch 722/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.4997\n",
      "Epoch 723/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.4970\n",
      "Epoch 724/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5024\n",
      "Epoch 725/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4996\n",
      "Epoch 726/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4976\n",
      "Epoch 727/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.4932\n",
      "Epoch 728/1000\n",
      "9389/9389 [==============================] - 1s 57us/sample - loss: 0.2500 - acc: 0.4990\n",
      "Epoch 729/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4979\n",
      "Epoch 730/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4991\n",
      "Epoch 731/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.4879\n",
      "Epoch 732/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.4964\n",
      "Epoch 733/1000\n",
      "9389/9389 [==============================] - 1s 57us/sample - loss: 0.2500 - acc: 0.4985\n",
      "Epoch 734/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5039\n",
      "Epoch 735/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.5074\n",
      "Epoch 736/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5040\n",
      "Epoch 737/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4980\n",
      "Epoch 738/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.4949\n",
      "Epoch 739/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4944\n",
      "Epoch 740/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.4966\n",
      "Epoch 741/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5044\n",
      "Epoch 742/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.5047\n",
      "Epoch 743/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5020\n",
      "Epoch 744/1000\n",
      "9389/9389 [==============================] - 1s 62us/sample - loss: 0.2500 - acc: 0.5028\n",
      "Epoch 745/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4989\n",
      "Epoch 746/1000\n",
      "9389/9389 [==============================] - 1s 75us/sample - loss: 0.2500 - acc: 0.5041\n",
      "Epoch 747/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4928\n",
      "Epoch 748/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4922\n",
      "Epoch 749/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4917\n",
      "Epoch 750/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.5019\n",
      "Epoch 751/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4992\n",
      "Epoch 752/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5028\n",
      "Epoch 753/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.5070\n",
      "Epoch 754/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.5038\n",
      "Epoch 755/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4961\n",
      "Epoch 756/1000\n",
      "9389/9389 [==============================] - 1s 57us/sample - loss: 0.2500 - acc: 0.5080\n",
      "Epoch 757/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4970\n",
      "Epoch 758/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.4942\n",
      "Epoch 759/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.4977\n",
      "Epoch 760/1000\n",
      "9389/9389 [==============================] - 1s 57us/sample - loss: 0.2500 - acc: 0.5015\n",
      "Epoch 761/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4986\n",
      "Epoch 762/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5015\n",
      "Epoch 763/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5114\n",
      "Epoch 764/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5001\n",
      "Epoch 765/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.4998\n",
      "Epoch 766/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5022\n",
      "Epoch 767/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4991\n",
      "Epoch 768/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.5034\n",
      "Epoch 769/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.5043\n",
      "Epoch 770/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.4970\n",
      "Epoch 771/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5039\n",
      "Epoch 772/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.4916\n",
      "Epoch 773/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4986\n",
      "Epoch 774/1000\n",
      "9389/9389 [==============================] - 1s 63us/sample - loss: 0.2500 - acc: 0.5037\n",
      "Epoch 775/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.5027\n",
      "Epoch 776/1000\n",
      "9389/9389 [==============================] - 1s 67us/sample - loss: 0.2500 - acc: 0.4986\n",
      "Epoch 777/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4955\n",
      "Epoch 778/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.4954\n",
      "Epoch 779/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5029\n",
      "Epoch 780/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4998\n",
      "Epoch 781/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.4982\n",
      "Epoch 782/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.4980\n",
      "Epoch 783/1000\n",
      "9389/9389 [==============================] - 1s 57us/sample - loss: 0.2500 - acc: 0.5074\n",
      "Epoch 784/1000\n",
      "9389/9389 [==============================] - 1s 64us/sample - loss: 0.2500 - acc: 0.5027\n",
      "Epoch 785/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.4947\n",
      "Epoch 786/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5041\n",
      "Epoch 787/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.5063\n",
      "Epoch 788/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5085\n",
      "Epoch 789/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.5022\n",
      "Epoch 790/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.5087\n",
      "Epoch 791/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5005\n",
      "Epoch 792/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4989\n",
      "Epoch 793/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4964\n",
      "Epoch 794/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.5066\n",
      "Epoch 795/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.4978\n",
      "Epoch 796/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.5015\n",
      "Epoch 797/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5011\n",
      "Epoch 798/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5040\n",
      "Epoch 799/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4929\n",
      "Epoch 800/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.4944\n",
      "Epoch 801/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.4961\n",
      "Epoch 802/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.4986\n",
      "Epoch 803/1000\n",
      "9389/9389 [==============================] - 1s 57us/sample - loss: 0.2500 - acc: 0.5074\n",
      "Epoch 804/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.4973\n",
      "Epoch 805/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.4976\n",
      "Epoch 806/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.5073\n",
      "Epoch 807/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.4970\n",
      "Epoch 808/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.4907\n",
      "Epoch 809/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4944\n",
      "Epoch 810/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.4974\n",
      "Epoch 811/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.5052\n",
      "Epoch 812/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.5002\n",
      "Epoch 813/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.4985\n",
      "Epoch 814/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5030\n",
      "Epoch 815/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4941\n",
      "Epoch 816/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.4972\n",
      "Epoch 817/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4964\n",
      "Epoch 818/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4997\n",
      "Epoch 819/1000\n",
      "9389/9389 [==============================] - 1s 57us/sample - loss: 0.2500 - acc: 0.4977\n",
      "Epoch 820/1000\n",
      "9389/9389 [==============================] - 1s 63us/sample - loss: 0.2500 - acc: 0.4976\n",
      "Epoch 821/1000\n",
      "9389/9389 [==============================] - 1s 96us/sample - loss: 0.2500 - acc: 0.4945\n",
      "Epoch 822/1000\n",
      "9389/9389 [==============================] - 1s 86us/sample - loss: 0.2500 - acc: 0.5100\n",
      "Epoch 823/1000\n",
      "9389/9389 [==============================] - 1s 63us/sample - loss: 0.2500 - acc: 0.5083\n",
      "Epoch 824/1000\n",
      "9389/9389 [==============================] - 1s 62us/sample - loss: 0.2500 - acc: 0.5068\n",
      "Epoch 825/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.4999\n",
      "Epoch 826/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.5029\n",
      "Epoch 827/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5045\n",
      "Epoch 828/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.4998\n",
      "Epoch 829/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.5042\n",
      "Epoch 830/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5008\n",
      "Epoch 831/1000\n",
      "9389/9389 [==============================] - 1s 67us/sample - loss: 0.2500 - acc: 0.4887\n",
      "Epoch 832/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4986\n",
      "Epoch 833/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.5022\n",
      "Epoch 834/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.4981\n",
      "Epoch 835/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.5076\n",
      "Epoch 836/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.4992\n",
      "Epoch 837/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.4948\n",
      "Epoch 838/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.5043\n",
      "Epoch 839/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.5047\n",
      "Epoch 840/1000\n",
      "9389/9389 [==============================] - 1s 68us/sample - loss: 0.2500 - acc: 0.4982\n",
      "Epoch 841/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5039\n",
      "Epoch 842/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.4964\n",
      "Epoch 843/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.5066\n",
      "Epoch 844/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.4979\n",
      "Epoch 845/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.4933\n",
      "Epoch 846/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.4923\n",
      "Epoch 847/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4950\n",
      "Epoch 848/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.5012\n",
      "Epoch 849/1000\n",
      "9389/9389 [==============================] - 1s 63us/sample - loss: 0.2500 - acc: 0.4912\n",
      "Epoch 850/1000\n",
      "9389/9389 [==============================] - 1s 62us/sample - loss: 0.2500 - acc: 0.4957\n",
      "Epoch 851/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.4983\n",
      "Epoch 852/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.4903\n",
      "Epoch 853/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.5003\n",
      "Epoch 854/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4980\n",
      "Epoch 855/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4944\n",
      "Epoch 856/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5004\n",
      "Epoch 857/1000\n",
      "9389/9389 [==============================] - 1s 63us/sample - loss: 0.2500 - acc: 0.4993\n",
      "Epoch 858/1000\n",
      "9389/9389 [==============================] - 1s 63us/sample - loss: 0.2500 - acc: 0.5045\n",
      "Epoch 859/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5074\n",
      "Epoch 860/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.4996\n",
      "Epoch 861/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.4943\n",
      "Epoch 862/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5054\n",
      "Epoch 863/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.5069\n",
      "Epoch 864/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4940\n",
      "Epoch 865/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.4926\n",
      "Epoch 866/1000\n",
      "9389/9389 [==============================] - 1s 64us/sample - loss: 0.2500 - acc: 0.5029\n",
      "Epoch 867/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5024\n",
      "Epoch 868/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.5006\n",
      "Epoch 869/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.5018\n",
      "Epoch 870/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.4977\n",
      "Epoch 871/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.4976\n",
      "Epoch 872/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.4969\n",
      "Epoch 873/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.5009\n",
      "Epoch 874/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.5013\n",
      "Epoch 875/1000\n",
      "9389/9389 [==============================] - 1s 64us/sample - loss: 0.2500 - acc: 0.4993\n",
      "Epoch 876/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.4974\n",
      "Epoch 877/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.4966\n",
      "Epoch 878/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.4933\n",
      "Epoch 879/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.4973\n",
      "Epoch 880/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5035\n",
      "Epoch 881/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.5031\n",
      "Epoch 882/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5037\n",
      "Epoch 883/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.4933\n",
      "Epoch 884/1000\n",
      "9389/9389 [==============================] - 1s 65us/sample - loss: 0.2500 - acc: 0.5024\n",
      "Epoch 885/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.5042\n",
      "Epoch 886/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4972\n",
      "Epoch 887/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.4960\n",
      "Epoch 888/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.5013\n",
      "Epoch 889/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.4970\n",
      "Epoch 890/1000\n",
      "9389/9389 [==============================] - 1s 67us/sample - loss: 0.2500 - acc: 0.4972\n",
      "Epoch 891/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4972\n",
      "Epoch 892/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.5099\n",
      "Epoch 893/1000\n",
      "9389/9389 [==============================] - 1s 66us/sample - loss: 0.2500 - acc: 0.4979\n",
      "Epoch 894/1000\n",
      "9389/9389 [==============================] - 1s 57us/sample - loss: 0.2500 - acc: 0.5071\n",
      "Epoch 895/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5060\n",
      "Epoch 896/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4981\n",
      "Epoch 897/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.4944\n",
      "Epoch 898/1000\n",
      "9389/9389 [==============================] - 1s 67us/sample - loss: 0.2500 - acc: 0.5058\n",
      "Epoch 899/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5008\n",
      "Epoch 900/1000\n",
      "9389/9389 [==============================] - 1s 62us/sample - loss: 0.2500 - acc: 0.4985\n",
      "Epoch 901/1000\n",
      "9389/9389 [==============================] - 1s 65us/sample - loss: 0.2500 - acc: 0.5003\n",
      "Epoch 902/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.5031\n",
      "Epoch 903/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.4942\n",
      "Epoch 904/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.5028\n",
      "Epoch 905/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5006\n",
      "Epoch 906/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4958\n",
      "Epoch 907/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4988\n",
      "Epoch 908/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4927\n",
      "Epoch 909/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.5003\n",
      "Epoch 910/1000\n",
      "9389/9389 [==============================] - 1s 62us/sample - loss: 0.2500 - acc: 0.4996\n",
      "Epoch 911/1000\n",
      "9389/9389 [==============================] - 1s 62us/sample - loss: 0.2500 - acc: 0.4978\n",
      "Epoch 912/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4990\n",
      "Epoch 913/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.5005\n",
      "Epoch 914/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.4978\n",
      "Epoch 915/1000\n",
      "9389/9389 [==============================] - 1s 57us/sample - loss: 0.2500 - acc: 0.4987\n",
      "Epoch 916/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.5057\n",
      "Epoch 917/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5006\n",
      "Epoch 918/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4952\n",
      "Epoch 919/1000\n",
      "9389/9389 [==============================] - 1s 64us/sample - loss: 0.2500 - acc: 0.5010\n",
      "Epoch 920/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.5002\n",
      "Epoch 921/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.4997\n",
      "Epoch 922/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4999\n",
      "Epoch 923/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4973\n",
      "Epoch 924/1000\n",
      "9389/9389 [==============================] - 1s 62us/sample - loss: 0.2500 - acc: 0.4978\n",
      "Epoch 925/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.5091\n",
      "Epoch 926/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.5025\n",
      "Epoch 927/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.4978\n",
      "Epoch 928/1000\n",
      "9389/9389 [==============================] - 1s 68us/sample - loss: 0.2500 - acc: 0.5150\n",
      "Epoch 929/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.4988\n",
      "Epoch 930/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.5001\n",
      "Epoch 931/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4976\n",
      "Epoch 932/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4991\n",
      "Epoch 933/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.4981\n",
      "Epoch 934/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.5041\n",
      "Epoch 935/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4954\n",
      "Epoch 936/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.5014\n",
      "Epoch 937/1000\n",
      "9389/9389 [==============================] - 1s 64us/sample - loss: 0.2500 - acc: 0.5028\n",
      "Epoch 938/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4928\n",
      "Epoch 939/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.5043\n",
      "Epoch 940/1000\n",
      "9389/9389 [==============================] - 1s 62us/sample - loss: 0.2500 - acc: 0.4996\n",
      "Epoch 941/1000\n",
      "9389/9389 [==============================] - 1s 62us/sample - loss: 0.2500 - acc: 0.5037\n",
      "Epoch 942/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.5053\n",
      "Epoch 943/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.5068\n",
      "Epoch 944/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4919\n",
      "Epoch 945/1000\n",
      "9389/9389 [==============================] - 1s 65us/sample - loss: 0.2500 - acc: 0.4995\n",
      "Epoch 946/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.4948\n",
      "Epoch 947/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.5008\n",
      "Epoch 948/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.5024\n",
      "Epoch 949/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5066\n",
      "Epoch 950/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.4957\n",
      "Epoch 951/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.5050\n",
      "Epoch 952/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.5047\n",
      "Epoch 953/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.5060\n",
      "Epoch 954/1000\n",
      "9389/9389 [==============================] - 1s 64us/sample - loss: 0.2500 - acc: 0.5045\n",
      "Epoch 955/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5055\n",
      "Epoch 956/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5029\n",
      "Epoch 957/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.50470s - loss: 0.2500 - a\n",
      "Epoch 958/1000\n",
      "9389/9389 [==============================] - 1s 66us/sample - loss: 0.2500 - acc: 0.5015\n",
      "Epoch 959/1000\n",
      "9389/9389 [==============================] - 1s 64us/sample - loss: 0.2500 - acc: 0.5037\n",
      "Epoch 960/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4985A: 0s - loss: 0.2500 - acc\n",
      "Epoch 961/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5029\n",
      "Epoch 962/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.5002\n",
      "Epoch 963/1000\n",
      "9389/9389 [==============================] - 1s 67us/sample - loss: 0.2500 - acc: 0.5110\n",
      "Epoch 964/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5047\n",
      "Epoch 965/1000\n",
      "9389/9389 [==============================] - 1s 62us/sample - loss: 0.2500 - acc: 0.4991\n",
      "Epoch 966/1000\n",
      "9389/9389 [==============================] - 1s 62us/sample - loss: 0.2500 - acc: 0.5022\n",
      "Epoch 967/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.4947\n",
      "Epoch 968/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5097\n",
      "Epoch 969/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.5027\n",
      "Epoch 970/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4953\n",
      "Epoch 971/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.5034\n",
      "Epoch 972/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4989\n",
      "Epoch 973/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4966\n",
      "Epoch 974/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4976\n",
      "Epoch 975/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.5039\n",
      "Epoch 976/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.4978\n",
      "Epoch 977/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4999\n",
      "Epoch 978/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.4965\n",
      "Epoch 979/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.4988\n",
      "Epoch 980/1000\n",
      "9389/9389 [==============================] - 1s 62us/sample - loss: 0.2500 - acc: 0.4895\n",
      "Epoch 981/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.5068\n",
      "Epoch 982/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.4993\n",
      "Epoch 983/1000\n",
      "9389/9389 [==============================] - 1s 62us/sample - loss: 0.2500 - acc: 0.5018\n",
      "Epoch 984/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.4976\n",
      "Epoch 985/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.5091\n",
      "Epoch 986/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.4952\n",
      "Epoch 987/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.4948\n",
      "Epoch 988/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4973\n",
      "Epoch 989/1000\n",
      "9389/9389 [==============================] - 1s 65us/sample - loss: 0.2500 - acc: 0.5024\n",
      "Epoch 990/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.5070\n",
      "Epoch 991/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.5031\n",
      "Epoch 992/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4941\n",
      "Epoch 993/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4996\n",
      "Epoch 994/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.5031\n",
      "Epoch 995/1000\n",
      "9389/9389 [==============================] - 1s 61us/sample - loss: 0.2500 - acc: 0.4992\n",
      "Epoch 996/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4947\n",
      "Epoch 997/1000\n",
      "9389/9389 [==============================] - 1s 60us/sample - loss: 0.2500 - acc: 0.4987\n",
      "Epoch 998/1000\n",
      "9389/9389 [==============================] - 1s 63us/sample - loss: 0.2500 - acc: 0.5063\n",
      "Epoch 999/1000\n",
      "9389/9389 [==============================] - 1s 58us/sample - loss: 0.2500 - acc: 0.5006\n",
      "Epoch 1000/1000\n",
      "9389/9389 [==============================] - 1s 59us/sample - loss: 0.2500 - acc: 0.4954\n",
      "2348/2348 [==============================] - 0s 51us/sample - loss: 0.2500 - acc: 0.0000e+00\n",
      "\n",
      "MODEL RESULTS\n",
      "\tTest accuracy:  0.0 Test loss:  0.25000003183314506\n",
      "PREDICTION RESULTS\n",
      "confusion matrix\n",
      "[[   0 1398]\n",
      " [   0  950]]\n",
      "\tF1:  0.576106731352 \tPrecission:  0.404599659284 \tRecall:  1.0\n"
     ]
    }
   ],
   "source": [
    "#Setting up the model layers\n",
    "#https://www.tensorflow.org/api_docs/python/tf/keras/layers\n",
    "#https://www.tensorflow.org/tutorials/keras/basic_classification\n",
    "\n",
    "model = keras.Sequential( [ keras.layers.Dense( 32, input_shape=( len(X[0]), ) ),\n",
    "                            keras.layers.Dense( 40, activation = tf.nn.sigmoid ),\n",
    "                            keras.layers.Dense( 10, activation = tf.nn.sigmoid ),\n",
    "                            keras.layers.Dense( 2, activation = tf.nn.softmax ) ] )\n",
    "\n",
    "#the optimazer has to minimize the loss function\n",
    "\n",
    "#Compiling the model\n",
    "  #Loss function  This measures how accurate the model is during training. We want to minimize \n",
    "                   #this function to \"steer\" the model in the right direction.\n",
    "  #Optimizer  This is how the model is updated based on the data it sees and its loss function.\n",
    "  #Metrics   Used to monitor the training and testing steps. The following example uses accuracy,\n",
    "              #the fraction of the images that are correctly classified.\n",
    "model.compile( optimizer = keras.optimizers.Adam(lr=0.001), loss = 'mean_squared_error', metrics = ['accuracy'] )\n",
    "#model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "num_cv_iterations = 1\n",
    "cv_object = ShuffleSplit( n_splits=num_cv_iterations, test_size = 0.2 )\n",
    "iter_num = 1\n",
    "\n",
    "for train_indices, test_indices in cv_object.split( X, y ):\n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    print \"\\n\\n====Iteration\",iter_num,\" ====\"\n",
    "    \n",
    "    model.fit( X_train, y_train, epochs=1000 )\n",
    "    test_loss, test_acc = model.evaluate( X_test, y_test )\n",
    "    y_pred = model.predict( X_test )\n",
    "    aux=[]\n",
    "    for i in range( len( y_pred ) ):\n",
    "        aux += [ np.argmax( y_pred[i] ) ]\n",
    "    conf = mt.confusion_matrix( y_test, aux )\n",
    "    \n",
    "    print '\\nMODEL RESULTS\\n\\tTest accuracy: ', test_acc, 'Test loss: ', test_loss\n",
    "    print \"PREDICTION RESULTS\"\n",
    "    print \"confusion matrix\\n\", conf\n",
    "    tp = float( conf[1][1] )\n",
    "    fp = float( conf[0][1] )\n",
    "    fn = float( conf[1][0] )\n",
    "    try:  \n",
    "        precission = tp / (tp + fp)\n",
    "        recall = tp / (tp + fn)\n",
    "        f1 = 2*precission*recall/(precission+recall)\n",
    "    except ArithmeticError:  \n",
    "        print (\"Arithmetic exception raised.\" )\n",
    "    else: \n",
    "        print \"\\tF1: \", f1, \"\\tPrecission: \", precission, \"\\tRecall: \", recall\n",
    "    iter_num+=1\n",
    "\n",
    "#print y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
