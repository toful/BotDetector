{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "sys.path.append( os.getcwd()+'/modules' )\n",
    "import aux_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Loading datasets\n",
    "path = os.getcwd() \n",
    "os.chdir( \"/home/toful/Documents/DataSets/cresci-2017.csv/datasets_full.csv/\" )\n",
    "\n",
    "real = pd.read_csv( 'genuine_accounts.csv/genuine_accounts.csv/users.csv' )\n",
    "real = real.fillna( '' )\n",
    "real['knownbot'] = 0\n",
    "\n",
    "fakeFollowers = pd.read_csv('fake_followers.csv/fake_followers.csv/users.csv', na_filter=False)\n",
    "fakeFollowers = fakeFollowers.fillna( '' )\n",
    "fakeFollowers['knownbot'] = 1\n",
    "\n",
    "df = pd.concat( [ real, fakeFollowers ], sort=False )\n",
    "df = shuffle( df )\n",
    "#print df.head()\n",
    "#print df.info()\n",
    "\n",
    "os.chdir( path )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6825, 17)\n",
      "                 id      lang-en  profile_pic  def_profile_pic  \\\n",
      "count  6.825000e+03  6825.000000       6825.0      6825.000000   \n",
      "mean   8.499737e+08     0.898022          0.0         0.002784   \n",
      "std    7.662248e+08     0.302642          0.0         0.052693   \n",
      "min    6.780330e+05     0.000000          0.0         0.000000   \n",
      "25%    2.597067e+08     1.000000          0.0         0.000000   \n",
      "50%    6.168972e+08     1.000000          0.0         0.000000   \n",
      "75%    1.174963e+09     1.000000          0.0         0.000000   \n",
      "max    3.164942e+09     1.000000          0.0         1.000000   \n",
      "\n",
      "       has_screen_name  30followers  1000friends  twice_num_followers  \\\n",
      "count      6825.000000  6825.000000  6825.000000          6825.000000   \n",
      "mean          0.000147     0.492601     0.076337             0.588425   \n",
      "std           0.012105     0.499982     0.265556             0.492155   \n",
      "min           0.000000     0.000000     0.000000             0.000000   \n",
      "25%           0.000000     0.000000     0.000000             0.000000   \n",
      "50%           0.000000     0.000000     0.000000             1.000000   \n",
      "75%           0.000000     1.000000     0.000000             1.000000   \n",
      "max           1.000000     1.000000     1.000000             1.000000   \n",
      "\n",
      "       fifty_FriendsFollowersRatio  hundred_FriendsFollowersRatio  \\\n",
      "count                  6825.000000                    6825.000000   \n",
      "mean                      0.091722                       0.051722   \n",
      "std                       0.288654                       0.221481   \n",
      "min                       0.000000                       0.000000   \n",
      "25%                       0.000000                       0.000000   \n",
      "50%                       0.000000                       0.000000   \n",
      "75%                       0.000000                       0.000000   \n",
      "max                       1.000000                       1.000000   \n",
      "\n",
      "            geoloc  banner_link     50tweets   20statuses  NeverTweeted  \\\n",
      "count  6825.000000  6825.000000  6825.000000  6825.000000   6825.000000   \n",
      "mean      0.663883     0.954725     0.410696     0.184615      0.020220   \n",
      "std       0.472414     0.207921     0.491996     0.388014      0.140762   \n",
      "min       0.000000     0.000000     0.000000     0.000000      0.000000   \n",
      "25%       0.000000     1.000000     0.000000     0.000000      0.000000   \n",
      "50%       1.000000     1.000000     0.000000     0.000000      0.000000   \n",
      "75%       1.000000     1.000000     1.000000     0.000000      0.000000   \n",
      "max       1.000000     1.000000     1.000000     1.000000      1.000000   \n",
      "\n",
      "       has_description     knownbot  \n",
      "count      6825.000000  6825.000000  \n",
      "mean          0.212747     0.490989  \n",
      "std           0.409280     0.499955  \n",
      "min           0.000000     0.000000  \n",
      "25%           0.000000     0.000000  \n",
      "50%           0.000000     0.000000  \n",
      "75%           0.000000     1.000000  \n",
      "max           1.000000     1.000000  \n",
      "['id' 'lang-en' 'profile_pic' 'def_profile_pic' 'has_screen_name'\n",
      " '30followers' '1000friends' 'twice_num_followers'\n",
      " 'fifty_FriendsFollowersRatio' 'hundred_FriendsFollowersRatio' 'geoloc'\n",
      " 'banner_link' '50tweets' '20statuses' 'NeverTweeted' 'has_description'\n",
      " 'knownbot']\n"
     ]
    }
   ],
   "source": [
    "#Building the working dataset\n",
    "score = pd.DataFrame()\n",
    "score['id'] = df['id']\n",
    "\n",
    "score['lang-en'] = df.apply( lambda row: aux_functions.language (row), axis=1 )\n",
    "score['profile_pic'] = df.apply( lambda row: aux_functions.profile_image (row), axis=1 ) #check this feature\n",
    "score['def_profile_pic'] = df.apply( lambda row: aux_functions.def_profile_image (row), axis=1 )\n",
    "score['has_screen_name'] = df.apply( lambda row: aux_functions.screen_name (row), axis=1 )\n",
    "score['30followers'] = df.apply( lambda row: aux_functions.min_followers (row, 30), axis=1 )\n",
    "score['1000friends'] = df.apply( lambda row: aux_functions.min_friends (row, 1000), axis=1 )\n",
    "score['twice_num_followers'] = df.apply( lambda row: aux_functions.ratio_followers (row), axis=1 )\n",
    "score['fifty_FriendsFollowersRatio'] = df.apply( lambda row: aux_functions.ratio_followers2 (row, 50), axis=1 )\n",
    "score['hundred_FriendsFollowersRatio'] = df.apply( lambda row: aux_functions.ratio_followers2 (row, 100), axis=1 )\n",
    "score['geoloc'] = df.apply( lambda row: aux_functions.location (row), axis=1 )\n",
    "score['banner_link'] = df.apply( lambda row: aux_functions.profile_banner (row), axis=1 )\n",
    "score['50tweets'] = df.apply( lambda row: aux_functions.tweets_written (row, 50), axis=1 )\n",
    "score['20statuses'] = df.apply( lambda row: aux_functions.min_statuses (row, 20), axis=1 )\n",
    "score['NeverTweeted'] = df.apply( lambda row: aux_functions.never_tweeted (row ), axis=1 )\n",
    "score['has_description'] = df.apply( lambda row: aux_functions.description (row), axis=1 )\n",
    "score['knownbot'] = df.apply( lambda row: aux_functions.knownbot (row), axis=1 )\n",
    "\n",
    "print score.shape\n",
    "print score.describe()\n",
    "print score.columns.values\n",
    "#score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics as mt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing the X and Y values for the machine learning analisis\n",
    "if 'knownbot' in score:\n",
    "    y = score['knownbot'].values # get the labels we want\n",
    "    del score['knownbot'] # get rid of the class label\n",
    "    X = score.values # use everything else to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====Iteration 0  ====\n",
      "RANDOM FOREST\n",
      "accuracy:  0.9838827838827838\n",
      "confusion matrix\n",
      "[[680   5]\n",
      " [ 17 663]]\n",
      "F1:  0.983679525223 \tPrecission:  0.99251497006 \tRecall:  0.975\n",
      "\n",
      "====Iteration 1  ====\n",
      "RANDOM FOREST\n",
      "accuracy:  0.9824175824175824\n",
      "confusion matrix\n",
      "[[695  13]\n",
      " [ 11 646]]\n",
      "F1:  0.981762917933 \tPrecission:  0.980273141123 \tRecall:  0.983257229833\n",
      "\n",
      "====Iteration 2  ====\n",
      "RANDOM FOREST\n",
      "accuracy:  0.9868131868131869\n",
      "confusion matrix\n",
      "[[708   7]\n",
      " [ 11 639]]\n",
      "F1:  0.986111111111 \tPrecission:  0.989164086687 \tRecall:  0.983076923077\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['models/randomForest_model.sav']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_cv_iterations = 3\n",
    "num_instances = len(y)\n",
    "cv_object = ShuffleSplit( n_splits=num_cv_iterations, test_size = 0.2 )\n",
    "\n",
    "# first we create a reusable logisitic regression and random forest objects\n",
    "lr_clf = LogisticRegression( penalty='l2', C=1.0, class_weight=None ) # get object\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=0)\n",
    "\n",
    "iter_num=0\n",
    "# the indices are the rows used for training and testing in each iteration\n",
    "for train_indices, test_indices in cv_object.split( X, y ):\n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    # train the reusable logisitc regression model on the training data\n",
    "    #lr_clf.fit( X_train, y_train ) # train object\n",
    "    #y_pred = lr_clf.predict( X_test ) # get test set precitions\n",
    "   \n",
    "    rf_clf.fit( X_train, y_train ) # train object\n",
    "    y_pred = rf_clf.predict( X_test ) # get test set precitions\n",
    "    acc = mt.accuracy_score( y_test, y_pred )\n",
    "    conf = mt.confusion_matrix( y_test, y_pred )\n",
    "    # now let's get the accuracy and confusion matrix for this iterations of training/testing\n",
    "    print \"\\n====Iteration\",iter_num,\" ====\"\n",
    "    print \"RANDOM FOREST\"\n",
    "    print \"accuracy: \", acc\n",
    "    print \"confusion matrix\\n\", conf\n",
    "    tp = float( conf[1][1] )\n",
    "    fp = float( conf[0][1] )\n",
    "    fn = float( conf[1][0] )\n",
    "    precission = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f1 = 2*precission*recall/(precission+recall)\n",
    "    print \"F1: \", f1, \"\\tPrecission: \", precission, \"\\tRecall: \", recall\n",
    "    iter_num+=1\n",
    "\n",
    "# save the model to disk\n",
    "if not os.path.exists( 'models' ):\n",
    "    os.makedirs( 'models' ) \n",
    "joblib.dump( rf_clf, 'models/randomForest_model.sav')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Setting up the model layers\n",
    "#https://www.tensorflow.org/api_docs/python/tf/keras/layers\n",
    "#https://www.tensorflow.org/tutorials/keras/basic_classification\n",
    "model = keras.Sequential( [ keras.layers.Dense( 32, input_shape=( len(X[0]), ) ),\n",
    "                            keras.layers.Dense( 40, activation = tf.nn.sigmoid ),\n",
    "                            keras.layers.Dense( 10, activation = tf.nn.sigmoid ),\n",
    "                            keras.layers.Dense( 2, activation = tf.nn.softmax ) ] )\n",
    "#model = keras.Sequential( )\n",
    "#model.add( keras.layers.Dense( 32, input_shape = ( len(X[0]), ) ) )\n",
    "#model.add( keras.layers.Dense( 2 ) )\n",
    "\n",
    "#the optimazer has to minimize the loss function\n",
    "\n",
    "#Compiling the model\n",
    "  #Loss function — This measures how accurate the model is during training. We want to minimize \n",
    "                   #this function to \"steer\" the model in the right direction.\n",
    "  #Optimizer — This is how the model is updated based on the data it sees and its loss function.\n",
    "  #Metrics —  Used to monitor the training and testing steps. The following example uses accuracy,\n",
    "              #the fraction of the images that are correctly classified.\n",
    "model.compile( optimizer = 'adam', \n",
    "               loss = 'mean_squared_error',\n",
    "               metrics = ['accuracy'] )\n",
    "\n",
    "num_cv_iterations = 3\n",
    "cv_object = ShuffleSplit( n_splits=num_cv_iterations, test_size = 0.2 )\n",
    "iter_num = 1\n",
    "\n",
    "for train_indices, test_indices in cv_object.split( X, y ):\n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    print \"\\n\\n====Iteration\",iter_num,\" ====\"\n",
    "    \n",
    "    model.fit( X_train, y_train, epochs=100 )\n",
    "    test_loss, test_acc = model.evaluate( X_test, y_test )\n",
    "    y_pred = model.predict( X_test )\n",
    "    aux=[]\n",
    "    for i in range( len( y_pred ) ):\n",
    "        aux += [ np.argmax( y_pred[i] ) ]\n",
    "    conf = mt.confusion_matrix( y_test, aux )\n",
    "    \n",
    "    print '\\nMODEL RESULTS\\n\\tTest accuracy: ', test_acc, 'Test loss: ', test_loss\n",
    "    print \"PREDICTION RESULTS\"\n",
    "    print \"confusion matrix\\n\", conf\n",
    "    tp = float( conf[1][1] )\n",
    "    fp = float( conf[0][1] )\n",
    "    fn = float( conf[1][0] )\n",
    "    try:  \n",
    "        precission = tp / (tp + fp)\n",
    "        recall = tp / (tp + fn)\n",
    "        f1 = 2*precission*recall/(precission+recall)\n",
    "    except ArithmeticError:  \n",
    "        print (\"Arithmetic exception raised.\" )\n",
    "    else: \n",
    "        print \"\\tF1: \", f1, \"\\tPrecission: \", precission, \"\\tRecall: \", recall\n",
    "    iter_num+=1\n",
    "\n",
    "#print y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
